#!/usr/bin/env python

import sys, os, datetime, urlparse, base64, getpass, collections, re, json, time, urllib, argparse, textwrap
import shlex # respects quoted substrings when splitting
import csv, codecs
import hashlib

import requests
from requests.auth import HTTPBasicAuth
from dxpy.utils.env import parse_user_env_file
from dxpy.utils.printing import *
from dxpy.utils.pretty_print import format_tree, format_table

try:
    import readline
except ImportError:
    print 'readline module not available'

state = {"interactive": False,
         "colors": "auto",
         "currentproj": None}
parser_map = {}

class ResultCounter():
    def __init__(self):
        self.counter = 0

    def __call__(self):
        self.counter += 1
        return ('\n' if self.counter > 1 else '') + UNDERLINE() + 'Result ' + \
            str(self.counter) + ':' + ENDC()

# TODO: Should we cache the user ID entered in the login phase?  or put it in an environment variable?

def try_call(func, *args, **kwargs):
    try:
        return func(*args, **kwargs)
    except BaseException as details:
        parser.exit(1, fill(unicode(details)) + '\n')

def get_bash_export_cmds(env_vars):
    string = ''
    for var in env_vars:
        string += 'export ' + var + '=' + "'" + env_vars[var] + "'\n"
    return string

def write_env_var(var, value):
    try:
        os.mkdir(os.path.expanduser('~/.dnanexus_config/'))
    except:
        pass
    if var in ['DX_APISERVER_HOST', 'DX_APISERVER_PORT', 'DX_APISERVER_PROTOCOL', 'DX_PROJECT_CONTEXT_ID', 'DX_WORKSPACE_ID', 'DX_SECURITY_CONTEXT']:
        env_vars = parse_user_env_file()
        env_vars[var] = value
        with open(os.path.expanduser('~/.dnanexus_config/') + 'environment', 'w') as fd:
            fd.write(fill('This file is automatically generated by the DNAnexus Command-line Client dx.  Edit it at your own risk.  See documentation on the CLI and environment variables for more information.', initial_indent='# ', subsequent_indent='# ', width=80) + '\n\n')
            fd.write(get_bash_export_cmds(env_vars))
    else: # DX_CLI_WD
        with open(os.path.expanduser('~/.dnanexus_config/' + var), 'w') as fd:
            fd.write(value)

def clearenv(args):
    if state['interactive']:
        parser.exit(1, 'Not allowed in interactive shell')
    try:
        os.remove(os.path.expanduser('~/.dnanexus_config/environment'))
    except:
        pass
    try:
        os.remove(os.path.expanduser('~/.dnanexus_config/DX_CLI_WD'))
    except:
        pass

def get_json_from_stdin():
    user_json_str = raw_input('Type JSON here> ')
    user_json = None
    try:
        user_json = json.loads(user_json_str)
    except:
        parser.exit(1, 'Error: user input could not be parsed as JSON\n')
        return None
    return user_json

def set_cli_colors(args=argparse.Namespace()):
    if 'color' in args:
        state['colors'] = args.color
    if state['colors'] == 'auto':
        set_colors(sys.stdout.isatty())
    else:
        set_colors(state['colors'] == 'on')

# Loading environment

#args_list = [unicode(arg, 'utf-8') for arg in sys.argv[1:]]
args_list = map(unicode, sys.argv[1:])

# Hard-coding a shortcut so that it won't print out the warning in
# import dxpy when clearing it anyway.
if len(args_list) == 1 and args_list[0] == 'clearenv':
    clearenv(argparse.Namespace())
    exit(0)

# importing dxpy will now appropriately load env variables
import dxpy
from dxpy.utils.resolver import *
from dxpy.utils.completer import *
from dxpy.utils.describe import *

# Loading other variables used for pretty-printing
if "LESS" in os.environ:
    os.environ["LESS"] = os.environ["LESS"] + " -RS"
else:
    os.environ["LESS"] = "-RS"

# This completer is for the command-line in the shell.  It assumes the
# first word is always a subcommand and that if the first word is a
# subcommand with further subcommands, then the second word must be an
# appropriate sub-subcommand.
class DXCLICompleter():
    subcommands = {'gtable': ['get '],
                   'find': ['jobs ', 'data ', 'projects ', 'apps '],
                   'new': ['record ', 'gtable ', 'project ']}

    def __init__(self):
        global subparsers
        self.commands = map(lambda subcmd: subcmd + ' ',
                            subparsers.choices.keys())
        self.matches = []
        self.text = None

    def get_command_matches(self, prefix):
        self.matches = filter(lambda command: command.startswith(prefix),
                              self.commands)

    def get_subcommand_matches(self, command, prefix):
        if command in self.subcommands:
            self.matches = map(lambda sub: command + ' ' + sub,
                               filter(lambda subcommand: subcommand.startswith(prefix),
                                      self.subcommands[command]))

    def __call__(self, text, state):
        if state == 0 and self.text != text:
            self.text = text
            space_pos = get_last_pos_of_char(' ', text)
            words = split_unescaped(' ', text)
            if len(words) > 0 and space_pos == len(text) - 1:
                words.append('')
            num_words = len(words)
            self.matches = []
            if num_words == 0:
                self.get_command_matches('')
            elif num_words == 1:
                self.get_command_matches(words[0])
            elif num_words == 2 and words[0] in self.subcommands:
                self.get_subcommand_matches(words[0], words[1])
            else:
                if words[0] == 'run':
                    path_matches = path_completer(words[-1],
                                                  classes=['applet'])
                elif words[0] in ['cd', 'rmdir', 'mkdir']:
                    path_matches = path_completer(words[-1],
                                                  expected='folder')
                elif words[0] in ['head']:
                    path_matches = path_completer(words[-1],
                                                  classes=['gtable', 'file'])
                elif words[0] in ['cat', 'upload']:
                    path_matches = path_completer(words[-1],
                                                  classes=['file'])
                elif words[0] in ['ls', 'rm', 'mv', 'cp']:
                    path_matches = path_completer(words[-1])
                elif words[0] in ['get_details', 'set_details', 'set_visibility', 'add_types', 'remove_types', 'close', 'get']:
                    path_matches = path_completer(words[-1])
                elif words[0] in ['describe', 'add_tags', 'remove_tags', 'rename', 'set_properties', 'unset_properties']:
                    path_matches = path_completer(words[-1], include_current_proj=True)
                elif words[0] in ['rmproject']:
                    path_matches = path_completer(words[-1], expected='project', include_current_proj=True)
                else:
                    path_matches = []

                self.matches = map(lambda match: text[:space_pos + 1] + match,
                                   path_matches)

                # Also find app name matches and append to
                # self.matches, preferably a list of installed apps
                if words[0] in ['run', 'install', 'uninstall']:
                    try:
                        app_names = map(lambda result:
                                            result['describe']['name'],
                                        filter(lambda result:
                                                   result['describe']['installed'] if words[0] in ['run', 'uninstall'] else not result['describe']['installed'],
                                               list(dxpy.find_apps(describe=True))))
                        app_matches = filter(lambda app_name:
                                                 app_name.startswith(words[-1]),
                                             app_names)
                        self.matches += map(lambda match:
                                                text[:space_pos + 1] + match,
                                            app_matches)
                    except:
                        pass

        if state < len(self.matches):
            return self.matches[state]
        else:
            return None

def login(args):
    if not state['interactive']:
        args.save = True

    # TODO: Remove this and replace with actual logic and interaction
    # when implemented
    if args.emtest:
        args.host = 'api.emtest.dev.dnanexus.com'
        args.port = 8081

    if args.host is not None or args.port is not None:
        authserver = 'http://' + args.host
        authserver += ':' + str(args.port)
        print 'Acquiring credentials from ' + authserver

        username = raw_input('Username: ')
        password = getpass.getpass()

        session = requests.session()

        response = ""
        try:
            response = session.post(authserver + "/direct_token", data={"grant_type": "authorization_code", "redirect_uri": "/"}, headers={"Authorization": "Basic " + base64.b64encode(username + ":" + password)})
            response.raise_for_status()
        except requests.exceptions.RequestException as details:
            print 'Error contacting the auth server: ' + unicode(details)
            parser.exit(1)
        token = json.loads(response.content)["access_token"]
        sec_context = '{"auth_token":"' + token + '","auth_token_type":"Bearer"}'
    elif args.token is None:
        authserver = 'https://auth.dnanexus.com'
        print 'Acquiring credentials from ' + authserver

        try:
            username = raw_input('Username: ')
            password = getpass.getpass()
        except:
            print ''
            parser.exit(1)
        auth = HTTPBasicAuth(username, password)

        session = requests.session()
        res = requests.post(authserver+"/oauth2/authorize",
                            data={"response_type": "code", "client_id": "test", "redirect_uri": "/"},
                            auth=auth,
                            allow_redirects=False)
        parsed_url = urlparse.parse_qs(urlparse.urlsplit(res.headers['Location'])[3])
        if 'code' not in parsed_url:
            parser.exit(1, 'Error: Incorrect username and/or password\n')
        else:
            code = parsed_url['code'][0]
        
        res = requests.post(authserver+"/oauth2/token",
                            data={"grant_type": "authorization_code", "code": code, "redirect_uri": "/"})
        assert(res.status_code == requests.codes.ok)
        token_res = json.loads(res.content)
        sec_context=json.dumps({'auth_token': token_res["access_token"], 'auth_token_type': token_res["token_type"]})
    else:
        sec_context = '{"auth_token":"' + args.token + '","auth_token_type":"Bearer"}'

    os.environ['DX_SECURITY_CONTEXT'] = sec_context
    dxpy.set_security_context(json.loads(sec_context))
    if args.save:
        write_env_var('DX_SECURITY_CONTEXT', sec_context)

    args.current = False
    setenv(args)

def logout(args):
    if dxpy.AUTH_HELPER is not None:
        if args.host is not None or args.port is not None:
            authserver = 'http://' + args.host
            authserver += ':' + str(args.port)
            print 'Deleting credentials from ' + authserver
        else:
            authserver = 'https://auth.dnanexus.com'
        session = requests.session()
        token = dxpy.AUTH_HELPER.security_context['auth_token']
        try:
            response = session.delete(authserver + '/authorizations/' + hashlib.sha256(token).hexdigest()[:7], auth=dxpy.AUTH_HELPER)
            response.raise_for_status()
        except BaseException as details:
            parser.exit(1, fill(unicode(details)) + '\n')
    else:
        parser.exit(1, 'No current auth token found\n')

def set_api(protocol, host, port, write):
    os.environ['DX_APISERVER_PROTOCOL'] = protocol
    os.environ['DX_APISERVER_HOST'] = host
    os.environ['DX_APISERVER_PORT'] = port
    if write:
        write_env_var("DX_APISERVER_PROTOCOL", protocol)
        write_env_var("DX_APISERVER_HOST", host)
        write_env_var("DX_APISERVER_PORT", port)
    dxpy.set_api_server_info(host=host, port=port, protocol=protocol)

def set_project(project, write):
    if dxpy.JOB_ID is None:
        os.environ['DX_PROJECT_CONTEXT_ID'] = project
        if write:
            write_env_var("DX_PROJECT_CONTEXT_ID", project)
    else:
        os.environ['DX_WORKSPACE_ID'] = project
        if write:
            write_env_var('DX_WORKSPACE_ID', project)
    dxpy.set_workspace_id(project)

def set_wd(folder, write):
    os.environ['DX_CLI_WD'] = folder
    if write:
        write_env_var("DX_CLI_WD", folder)

# Will raise KeyboardInterrupt, EOFError
def prompt_for_var(prompt_str, env_var_str):
    prompt = prompt_str
    default = None
    if env_var_str in os.environ:
        default = os.environ[env_var_str]
        prompt += ' [' + default + ']: '
    else:
        prompt += ': '
    while True:
        value = raw_input(prompt)
        if value != '':
            return value
        elif default is not None:
            return default

def pick_and_set_project(args):
    try:
        results = list(dxpy.find_projects(describe=True))
    except BaseException as details:
        parser.exit(1, fill('Error when listing available projects: ' + unicode(details)) + '\n')

    projects = map(lambda result: result['id'], results)
    if len(projects) == 0:
        parser.exit(1, 'No projects to choose from.  Please create one first using "dx new project".\n')

    # Eliminate current default if it is not a found project
    try:
        default = projects.index(dxpy.WORKSPACE_ID)
    except:
        default = None

    print ""
    print "Available projects:"
    choice = try_call(pick,
                      map(lambda result:
                              result['describe']['name'] + ' (' + result['level'] + ')',
                          results),
                      default)

    print 'Setting current project to: ' + results[choice]['describe']['name']
    set_project(projects[choice], not state['interactive'])
    state['currentproj'] = results[choice]['describe']['name']
    set_wd('/', not state['interactive'])

def setenv(args):
    if not state['interactive']:
        args.save = True
    if args.current:
        env_vars = ['DX_SECURITY_CONTEXT', 'DX_APISERVER_HOST', 'DX_APISERVER_PORT', 'DX_PROJECT_CONTEXT_ID', 'DX_CLI_WD', 'DX_WORKSPACE_ID']
        for var in env_vars:
            if var in os.environ:
                write_env_var(var, os.environ[var])
    else:
        try:
            api_protocol = prompt_for_var('API server protocol (choose "http" or "https")', 'DX_APISERVER_PROTOCOL')
            api_host = prompt_for_var('API server host', 'DX_APISERVER_HOST')
            api_port = prompt_for_var('API server port', 'DX_APISERVER_PORT')
            set_api(api_protocol, api_host, api_port, args.save)
        except:
            parser.exit(1, '\n')

    if args.projects:
        pick_and_set_project(args)

def env(args):
    if args.bash:
        if dxpy.AUTH_HELPER is not None:
            print "export DX_SECURITY_CONTEXT='" + json.dumps(dxpy.AUTH_HELPER.security_context) + "'"
        if dxpy.APISERVER_PROTOCOL is not None:
            print "export DX_APISERVER_PROTOCOL=" + dxpy.APISERVER_PROTOCOL
        if dxpy.APISERVER_HOST is not None:
            print "export DX_APISERVER_HOST=" + dxpy.APISERVER_HOST
        if dxpy.APISERVER_PORT is not None:
            print "export DX_APISERVER_PORT=" + dxpy.APISERVER_PORT
    else:
        if dxpy.AUTH_HELPER is not None:
            print "Auth token used\t\t" + dxpy.AUTH_HELPER.security_context.get("auth_token", "none")
        print "API server protocol\t" + dxpy.APISERVER_PROTOCOL
        print "API server host\t\t" + dxpy.APISERVER_HOST
        print "API server port\t\t" + dxpy.APISERVER_PORT
        print "Current workspace\t" + str(dxpy.WORKSPACE_ID)
        print "Current folder\t\t" + str(os.environ.get("DX_CLI_WD"))

def get_pwd():
    pwd_str = None
    if dxpy.WORKSPACE_ID is not None:
        if state['currentproj'] is None:
            try:
                proj_name = dxpy.DXHTTPRequest('/' + dxpy.WORKSPACE_ID + '/describe', {})['name']
                state['currentproj'] = proj_name
            except:
                pass
    if state['currentproj'] is not None:
        pwd_str = state['currentproj'] + ':' + os.environ.get('DX_CLI_WD', '/')
    return pwd_str

def pwd(args):
    pwd_str = get_pwd()
    if pwd_str is not None:
        print pwd_str
    else:
        parser.exit(1, 'Current project is not set\n')

def get_output_flag(args):
    if not args.brief and not args.summary and not args.verbose:
        args.summary = True

def api(args):
    json_input = json.loads(args.input_json)
    if args.input is not None:
        with open(args.input, 'r') as fd:
            data = fd.read()
            try:
                json_input = json.loads(data)
            except:
                parser.exit(1, 'Error: file contents could not be parsed as JSON\n')
    elif args.stdin:
        json_input = get_json_from_stdin()
        if json_input == None:
            return
    resp = None
    try:
        resp = dxpy.DXHTTPRequest('/' + args.resource + '/' + args.method,
                                  json_input)
        print json.dumps(resp, indent=4)
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(unicode(details)) + '\n')

def invite(args):
    project, none, none = try_call(resolve_existing_path,
                                   args.project, 'project')
    try:
        resp = dxpy.DXHTTPRequest('/' + project + '/invite',
                                  {"invitee": args.user, "level": args.level})
        print 'Invited ' + args.user + ' to ' + project + ' (' + resp['state'] + ')'
    except BaseException as details:
        parser.exit(1, fill(unicode(details)) + '\n')

def cd(args):
    # entity_result should be None because expected='folder'
    project, folderpath, none = try_call(resolve_existing_path,
                                         args.path, 'folder')

    if project is not None:
        # It is obvious what the project is
        if project != dxpy.WORKSPACE_ID:
            # And it's different so we need to take action
            set_project(project, not state['interactive'])
            proj_indicator = args.path[: get_last_pos_of_char(':', args.path) ]
            if is_container_id(proj_indicator):
                state['currentproj'] = None
            else:
                state['currentproj'] = proj_indicator
    else:
        parser.exit(1, 'Error: No current project was given\n')

    # TODO: attempt to add caching later if it's an issue
    # if project in cached_project_paths and folderpath in cached_project_paths[project]:
    #     set_wd(folderpath, not interactive)

    try:
        dxproj = dxpy.get_handler(dxpy.WORKSPACE_ID)
        dxproj.list_folder(folder=folderpath)
    except:
        parser.exit(1, fill(folderpath + ': No such file or directory found in project ' + dxpy.WORKSPACE_ID) + '\n')
        return

    set_wd(folderpath, not state['interactive'])

def cmp_names(x, y):
    return cmp(x['describe']['name'].lower(), y['describe']['name'].lower())

def ls(args):
    project, folderpath, entity_results = try_call(resolve_existing_path,
                                                   args.path,
                                                   ask_to_resolve=False)

    if project is None:
        parser.exit(1, fill('Current project must be set or specified before any data can be listed') + '\n')
    dxproj = dxpy.get_handler(project)
    only = ""
    if args.obj and not args.folders and not args.full:
        only = "objects"
    elif not args.obj and args.folders and not args.full:
        only = "folders"
    else:
        only = "all"

    resp = None
    if entity_results is None:
        try:
            resp = dxproj.list_folder(folder=folderpath,
                                      describe={},
                                      only=only,
                                      includeHidden=args.all)

            # Listing the folder was successful

            if args.long:
                print UNDERLINE() + 'Project:' + ENDC() + ' ' + dxproj.describe()['name'] + ' (' + project + ')'
                print UNDERLINE() + 'Folder :' + ENDC() + ' ' + folderpath

            if not args.obj:
                folders_to_print = ['/.', '/..'] if args.all else []
                folders_to_print += resp['folders']
                for folder in folders_to_print:
                    if args.full:
                        print BOLD() + BLUE() + folder + ENDC()
                    else:
                        print BOLD() + BLUE() + os.path.basename(folder) + '/' + ENDC()
            if not args.folders:
                # if project not in cached_project_paths:
                #     cached_project_paths[project] = {}
                # cached_project_paths[project][folderpath] = {}

                resp["objects"].sort(cmp=cmp_names)
                last_name = None
                next_name = None
                if args.long:
                    if len(resp['objects']) > 0:
                        print BOLD() + 'State\tLast modified       Size     Name (ID)' + ENDC()
                    else:
                        print "No data objects found in the folder"
                for i in range(len(resp["objects"])):
                    if args.brief:
                        print resp['objects'][i]['id']
                    else:
                        current_name = resp['objects'][i]['describe']['name']
                        if i < len(resp['objects']) - 1:
                            next_name = resp['objects'][i + 1]['describe']['name']
                        else:
                            next_name = None
                        addendum = ''

                        if last_name is not None and last_name == current_name:
                            addendum = ' : ' + resp['objects'][i]['id']
                        #     cached_project_paths[project][folderpath][current_name].append(resp['objects'][i]['id'])
                        else:
                            #     cached_project_paths[project][folderpath][current_name] = [resp['objects'][i]['id']]
                            if next_name is not None and current_name == next_name:
                                addendum = ' : ' + resp['objects'][i]['id']

                        if args.long:
                            print_ls_l_desc(resp['objects'][i]['describe'])
                        else:
                            if resp['objects'][i]['describe']['class'] == 'applet':
                                print BOLD() + GREEN() + resp['objects'][i]['describe']['name'] + ENDC() + addendum
                            else:
                                print resp['objects'][i]['describe']['name'] + addendum

                        last_name = current_name
        except BaseException as details:
            parser.exit(1, fill(unicode(details)) + '\n')
    else:
        # We have results to describe
        for result in entity_results:
            if args.brief:
                print result['id']
            else:
                print_ls_l_desc(result['describe'])

def mkdir(args):
    had_error = False
    for path in args.paths:
        # Resolve the path and add it to the list
        try:
            project, folderpath, none = resolve_path_with_project(path, expected='folder')
        except BaseException as details:
            print fill('Could not resolve \"' + path + '\": ' + unicode(details))
            had_error = True
            continue
        if project is None:
            print fill('Could not resolve the project of \"' + path + '\"')
        try:
            dxpy.DXHTTPRequest('/' + project + '/newFolder', {"folder": folderpath})
        except BaseException as details:
            print "Error while creating " + folderpath + " in " + project
            print "  " + unicode(details)
            had_error = True
    if had_error:
        parser.exit(1)

def rmdir(args):
    had_error = False
    for path in args.paths:
        try:
            project, folderpath, none = resolve_path_with_project(path, expected='folder')
        except BaseException as details:
            print fill('Could not resolve \"' + path + '\": ' + unicode(details))
            had_error = True
            continue
        if project is None:
            print fill('Could not resolve the project of \"' + path + '\"')
        try:
            dxpy.DXHTTPRequest('/' + project + '/removeFolder', {"folder": folderpath})
        except BaseException as details:
            print "Error while removing " + folderpath + " in " + project
            print "  " + unicode(details)
            had_error = True
    if had_error:
        parser.exit(1)

def rm(args):
    had_error = False
    projects = {}
    for path in args.paths:
        # Resolve the path and add it to the list
        try:
            project, folderpath, entity_results = resolve_existing_path(path, allow_mult=True)
        except BaseException as details:
            print fill('Could not resolve \"' + path + '\": ' + unicode(details))
            had_error = True
            continue
        if project is None:
            had_error = True
            print fill('Could not resolve \"' + path + '\" to a project')
            continue
        if project not in projects:
            projects[project] = {"folders": [], "objects": []}
        if entity_results is None:
            if folderpath is not None:
                if not args.recursive:
                    print fill(u'Did not find \"' + path + '\" as a data object; if it is a folder, cannot remove it without setting the \"-r\" flag')
                    had_error = True
                    continue
                else:
                    projects[project]['folders'].append(folderpath)
            else:
                print fill('Path ' + path + ' resolved to a project; cannot remove a project using \"rm\"')
                had_error = True
                continue
        else:
            projects[project]['objects'] += map(lambda result: result['id'],
                                                entity_results)

    for project in projects:
        for folder in projects[project]['folders']:
            try:
                dxpy.DXHTTPRequest('/' + project + '/removeFolder',
                                   {"folder": folder,
                                    "recurse": True})
            except BaseException as details:
                print "Error while removing " + folder + " from " + project
                print "  " + unicode(details)
                had_error = True
        try:
            dxpy.DXHTTPRequest('/' + project + '/removeObjects',
                               {"objects": projects[project]['objects']})
        except BaseException as details:
            print "Error while removing " + json.dumps(projects[project]['objects']) + " from " + project
            print "  " + unicode(details)
            had_error = True
    if had_error:
        parser.exit(1)

def rmproject(args):
    had_error = False
    for project in args.projects:
        # Be forgiving if they offer an extraneous colon
        substrings = split_unescaped(':', project)
        if len(substrings) > 1 or (len(substrings) == 1 and project[0] == ':'):
            print fill('Was unable to remove \"' + project + '\": a nonempty string was found to the right of an unescaped colon')
            had_error = True
            continue
        if len(substrings) == 0:
            if project[0] == ':':
                print fill('Unable to remove \":\": to remove the current project, use its name or ID')
                had_error = True
                continue
        proj_id = resolve_container_id_or_name(substrings[0])
        if proj_id is None:
            print fill('Was unable to remove \"' + project + '\": could not resolve to a project ID')
            had_error = True
            continue
        try:
            proj_desc = dxpy.DXHTTPRequest('/' + proj_id + '/describe', {})
            value = raw_input(fill('About to delete project \"' + proj_desc['name'] + '\" (' + proj_id + ')') + '\nPlease confirm [yes/no]: ')
            if value.lower() != 'yes':
                print fill('Aborting deletion of project \"' + proj_desc['name'] + '\"')
                continue
            dxpy.DXHTTPRequest('/' + proj_id + '/destroy', {})
            print fill('Successfully deleted project \"' + proj_desc['name'] + '\"')
        except EOFError:
            print ''
            parser.exit(1)
        except KeyboardInterrupt:
            print ''
            parser.exit(1)
        except BaseException as details:
            print fill('Was unable to remove ' + project + ', ' + unicode(details))
            had_error = True
    if had_error:
        parser.exit(1)

# ONLY for within the SAME project.  Will exit fatally otherwise.
def mv(args):
    try:
        dest_proj, dest_path, none = try_call(resolve_path_with_project,
                                              args.destination, 'folder')
        if dest_path is None:
            raise ValueError()
        dx_dest = dxpy.get_handler(dest_proj)
        dx_dest.list_folder(folder=dest_path, only='folders')
    except:
        if dest_path is None:
            parser.exit(1, 'Cannot move to a hash ID\n')
        # Destination folder path is new => renaming
        if len(args.sources) != 1:
            # Can't rename more than one object
            parser.exit(1, 'The destination folder does not exist\n')
        last_slash_pos = get_last_pos_of_char('/', dest_path)
        if last_slash_pos == 0:
            dest_folder = '/'
        else:
            dest_folder = dest_path[:last_slash_pos]
        dest_name = dest_path[last_slash_pos + 1:].replace('\/', '/')
        try:
            dx_dest.list_folder(folder=dest_folder, only='folders')
        except:
            parser.exit(1, 'The destination folder does not exist\n')

        # Either rename the data object or rename the folder
        src_proj, src_path, src_results = try_call(resolve_existing_path,
                                                   args.sources[0],
                                                   allow_mult=True)

        if src_proj != dest_proj:
            parser.exit(1, 'Using \"mv\" for moving something from one project to another is unsupported.\n')

        if src_results is None:
            if src_path == '/':
                parser.exit(1, fill('Cannot rename root folder; to rename the project, use the "dx rename" subcommand.') + '\n')
            try:
                dxpy.DXHTTPRequest('/' + src_proj + '/renameFolder',
                                   {"folder": src_path,
                                    "newpath": dest_path})
                return
            except BaseException as details:
                parser.exit(1, fill(unicode(details)) + '\n')
        else:
            try:
                if src_results[0]['describe']['folder'] != dest_folder:
                    dxpy.DXHTTPRequest('/' + src_proj + '/move',
                                       {"objects": map(lambda result:
                                                           result['id'],
                                                       src_results),
                                        "destination": dest_folder})
                for result in src_results:
                    dxpy.DXHTTPRequest('/' + result['id'] + '/rename',
                                       {"project": src_proj,
                                        "name": dest_name})
                return
            except BaseException as details:
                parser.exit(1, fill(unicode(details)) + '\n')

    if len(args.sources) == 0:
        parser.exit(1, 'No sources provided to move\n')
    src_objects = []
    src_folders = []
    for source in args.sources:
        src_proj, src_folderpath, src_results = try_call(resolve_existing_path,
                                                         source,
                                                         allow_mult=True)
        if src_proj != dest_proj:
            parser.exit(1, fill('Using \"mv\" for moving something from one project to another is unsupported.  Use \"cp\" and \"rm\".') + '\n')

        if src_results is None:
            src_folders.append(src_folderpath)
        else:
            src_objects += map(lambda result: result['id'], src_results)
    try:
        dxpy.DXHTTPRequest('/' + src_proj + '/move',
                           {"objects": src_objects,
                            "folders": src_folders,
                            "destination": dest_path})
    except BaseException as details:
        parser.exit(1, fill(unicode(details)) + '\n')

# ONLY for between DIFFERENT projects.  Will exit fatally otherwise.
def cp(args):
    try:
        dest_proj, dest_path, none = try_call(resolve_path_with_project,
                                              args.destination, 'folder')
        if dest_path is None:
            raise ValueError()
        dx_dest = dxpy.get_handler(dest_proj)
        dx_dest.list_folder(folder=dest_path, only='folders')
    except:
        if dest_path is None:
            parser.exit(1, 'Cannot copy to a hash ID\n')
        # Destination folder path is new => renaming
        if len(args.sources) != 1:
            # Can't copy and rename more than one object
            parser.exit(1, 'The destination folder does not exist\n')
        last_slash_pos = get_last_pos_of_char('/', dest_path)
        if last_slash_pos == 0:
            dest_folder = '/'
        else:
            dest_folder = dest_path[:last_slash_pos]
        dest_name = dest_path[last_slash_pos + 1:].replace('\/', '/')
        try:
            dx_dest.list_folder(folder=dest_folder, only='folders')
        except:
            parser.exit(1, 'The destination folder does not exist\n')

        # Clone and rename either the data object or the folder
        # src_result is None if it could not be resolved to an object
        src_proj, src_path, src_results = try_call(resolve_existing_path,
                                                   args.sources[0],
                                                   allow_mult=True)
        if src_proj == dest_proj:
            parser.exit(1, fill('A source path and the destination path resolved to the same project or container.  Please specify different source and destination containers, e.g.') + '\n  dx cp source-project:source-id-or-path dest-project:dest-path' + '\n')

        if src_results is None:
            try:
                contents = dxpy.DXHTTPRequest('/' + src_proj + '/listFolder',
                                              {"folder": src_path,
                                               "includeHidden": True})
                dxpy.DXHTTPRequest('/' + dest_proj + '/newFolder',
                                   {"folder": dest_path})
                exists = dxpy.DXHTTPRequest('/' + src_proj + '/clone',
                                          {"folders": contents['folders'],
                                           "objects": map(lambda result: result['id'], contents['objects']),
                                           "project": dest_proj,
                                           "destination": dest_path})['exists']
                if len(exists) > 0:
                    print fill('The following objects already existed in the destination container and were left alone:') + '\n ' + '\n '.join(json.dumps(exists))
                return
            except BaseException as details:
                parser.exit(1, fill(unicode(details)) + '\n')
        else:
            try:
                exists = dxpy.DXHTTPRequest('/' + src_proj + '/clone',
                                            {"objects": map(lambda result: result['id'],
                                                            src_results),
                                             "project": dest_proj,
                                             "destination": dest_folder})['exists']
                if len(exists) > 0:
                    print fill('The following objects already existed in the destination container and were left alone:') + '\n ' + '\n '.join(json.dumps(exists))
                for result in src_results:
                    if result['id'] not in exists:
                        dxpy.DXHTTPRequest('/' + result['id'] + '/rename',
                                           {"project": dest_proj,
                                            "name": dest_name})
                return
            except BaseException as details:
                parser.exit(1, fill(unicode(details)) + '\n')

    if len(args.sources) == 0:
        parser.exit(1, 'No sources provided to copy to another project\n')
    src_objects = []
    src_folders = []
    for source in args.sources:
        src_proj, src_folderpath, src_results = try_call(resolve_existing_path,
                                                         source,
                                                         allow_mult=True)
        if src_proj == dest_proj:
            parser.exit(1, fill('A source path and the destination path resolved to the same project or container.  Please specify different source and destination containers, e.g.') + '\n  dx cp source-project:source-id-or-path dest-project:dest-path' + '\n')

        if src_results is None:
            src_folders.append(src_folderpath)
        else:
            src_objects += map(lambda result: result['id'], src_results)
    try:
        exists = dxpy.DXHTTPRequest('/' + src_proj + '/clone',
                                    {"objects": src_objects,
                                     "folders": src_folders,
                                     "project": dest_proj,
                                     "destination": dest_path})['exists']
        if len(exists) > 0:
            print fill('The following objects already existed in the destination container and were left alone:') + '\n ' + '\n '.join(exists)        
    except BaseException as details:
        parser.exit(1, fill(unicode(details)) + '\n')

def tree(args):
    project, folderpath, none = try_call(resolve_existing_path, args.path,
                                         expected='folder')

    if project is None:
        parser.exit(1, fill('Current project must be set or specified before any data can be listed') + '\n')
    dxproj = dxpy.get_handler(project)

    tree = collections.OrderedDict()
    try:
        folders = filter(lambda folder: folder.startswith((folderpath + '/') if folderpath != '/' else '/'),
                           dxproj.describe(input_params={"folders": True})['folders'])
        folders = [ folder[len(folderpath):] for folder in folders ]
        for folder in folders:
            subtree = tree
            for path_element in folder.split("/"):
                if path_element == "":
                    continue
                path_element_desc = BOLD() + BLUE() + path_element + ENDC()
                subtree.setdefault(path_element_desc, collections.OrderedDict())
                subtree = subtree[path_element_desc]

        for item in sorted(dxpy.find_data_objects(project=project, folder=folderpath,
                                                  recurse=True, describe=True),
                           cmp_names):
            subtree = tree
            for path_element in item['describe']['folder'][len(folderpath):].split("/"):
                if path_element == "":
                    continue
                path_element_desc = BOLD() + BLUE() + path_element + ENDC()
                subtree = subtree[path_element_desc]
            if args.long:
                item_desc = get_ls_l_desc(item['describe'])
            else:
                item_desc = item['describe']['name']
                if item['describe']['class'] == 'applet':
                    item_desc = BOLD() + GREEN() + item_desc + ENDC()
            subtree[item_desc] = None

        print format_tree(tree, root=args.path)
    except BaseException as details:
        parser.exit(1, fill(unicode(details)) + '\n')

def describe(args):
    # Attempt to resolve name
    # First, if it looks like a hash id, do that.
    json_input = {}
    json_input["properties"] = True
    if args.details:
        json_input["details"] = True
    if is_data_obj_id(args.path):
        # Should prefer the current project's version if possible
        if dxpy.WORKSPACE_ID is not None:
            json_input['project'] = dxpy.WORKSPACE_ID

    # Otherwise, attempt to look for it as a data object.
    try:
        project, folderpath, entity_results = resolve_existing_path(args.path,
                                                                    expected='entity',
                                                                    ask_to_resolve=False,
                                                                    describe=json_input)
    except:
        project, folderpath, entity_results = None, None, None

    found_match = False

    json_output = []

    get_result_str = ResultCounter()

    # Could be a project
    if entity_results is None:
        if args.path[-1] == ':':
            # It is the project.
            try:
                desc = dxpy.DXHTTPRequest('/' + project + '/describe',
                                          json_input)
                found_match = True
                if args.json:
                    json_output.append(desc)
                else:
                    print get_result_str()
                    print_desc(desc)
            except:
                pass
        elif is_container_id(args.path):
            try:
                desc = dxpy.DXHTTPRequest('/' + args.path + '/describe',
                                          json_input)
                found_match = True
                if args.json:
                    json_output.append(desc)
                else:
                    print get_result_str()
                    print_desc(desc)
            except:
                pass

    # Found data object or is an id
    if entity_results is not None:
        if len(entity_results) > 0:
            found_match = True
        for result in entity_results:
            if args.json:
                json_output.append(result['describe'])
            else:
                print get_result_str()
                print_desc(result['describe'])

    if not is_hashid(args.path):

        # Could be an app name
        if args.path.startswith('app-'):
            try:
                desc = dxpy.DXHTTPRequest('/' + args.path + '/describe', {})
                if args.json:
                    json_output.append(desc)
                else:
                    print get_result_str()
                    print_desc(desc)
                found_match = True
            except:
                pass
        else:
            for result in dxpy.find_apps(name=args.path, describe=True):
                if args.json:
                    json_output.append(result['describe'])
                else:
                    print get_result_str()
                    print_desc(result['describe'])
                found_match = True

        # Could be a user
        if args.path.startswith('user'):
            try:
                desc = dxpy.DXHTTPRequest('/' + args.path + '/describe', {"appsInstalled": True, "subscriptions": True})
                found_match = True
                if args.json:
                    json_output.append(desc)
                else:
                    print get_result_str()
                    print_desc(desc)
            except dxpy.DXAPIError as details:
                pass

        # Could be an org or team
        if args.path.startswith('org-') or args.path.startswith('team-'):
            try:
                desc = dxpy.DXHTTPRequest('/' + args.path + '/describe', {})
                found_match = True
                if args.json:
                    json_output.append(desc)
                else:
                    print get_result_str()
                    print_desc(desc)
            except dxpy.DXAPIError as details:
                pass

    if args.json:
        if args.multi:
            print json.dumps(json_output, indent=4)
        elif len(json_output) > 1:
            parser.exit(1, fill('More than one match found for ' + args.path + '; to get all of them in JSON format, also provide the --multi flag.') + '\n')
        elif len(json_output) == 0:
            parser.exit(1, fill('No match found for ' + args.path) + '\n')
        else:
            print json.dumps(json_output[0], indent=4)
    elif not found_match:
        print "No matches found for " + args.path

def get_properties_from_args(args_properties):
    properties = None
    if args_properties is not None:
        properties = {}
        for keyeqval in args_properties:
            try:
                key, val = split_unescaped('=', keyeqval)
            except:
                parser.exit(1, fill('Property key-value pair must be given using syntax "property_key=property_value"'))
            properties[key] = val
    return properties

def new_project(args):
    get_output_flag(args)
    try:
        resp = dxpy.DXHTTPRequest('/project/new',
                                  {"name": args.name})
        if args.brief:
            print resp['id']
        else:
            print fill('Created new project called \"' + args.name + '\" (' + resp['id'] + ')')
    except BaseException as details:
        parser.exit(1, fill(unicode(details)) + '\n')

def new_record(args):
    hidden = (args.visibility == 'hidden')
    properties = get_properties_from_args(args.properties)
    details = None
    if args.details is not None:
        try:
            details = json.loads(args.details)
        except:
            parser.exit(1, 'Error: details could not be parsed as JSON\n')
    init_from = None
    if args.init is not None:
        init_from = dxpy.DXRecord(args.init)

    dxrecord = None
    try:
        dxrecord = dxpy.new_dxrecord(project=args.project, name=args.name,
                                     tags=args.tags, types=args.types, 
                                     hidden=hidden, properties=properties,
                                     details=details,
                                     folder=args.folder,
                                     parents=args.parents, init_from=init_from)
        print dxrecord.get_id()
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(unicode(details)) + '\n')

def new_gtable(args):
    hidden = (args.visibility == 'hidden')
    properties = get_properties_from_args(args.properties)
    details = None
    if args.details is not None:
        try:
            details = json.loads(args.details)
        except:
            parser.exit(1, 'Error: details could not be parsed as JSON\n')

    json_input = {}
    if args.input is not None:
        with open(args.input, 'r') as fd:
            data = fd.read()
            json_input = json.loads(data)

    if 'columns' in json_input:
        args.columns = json_input['columns']
    elif args.columns is not None:
        args.columns = json.loads(args.columns)
    if 'indices' in json_input:
        args.indices = json_input['indices']
    elif args.indices is not None:
        args.indices = json.loads(args.indices)

    try:
        dxgtable = dxpy.new_dxgtable(project=args.project, name=args.name,
                                     tags=args.tags, types=args.types, 
                                     hidden=hidden, properties=properties,
                                     details=details,
                                     folder=args.folder,
                                     parents=args.parents,
                                     columns=args.columns,
                                     indices=args.indices)
        print dxgtable.get_id()
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(unicode(details)) + '\n')

def set_visibility(args):
    had_error = False
    # Attempt to resolve name
    project, folderpath, entity_results = try_call(resolve_existing_path,
                                                   args.path,
                                                   expected='entity',
                                                   allow_mult=True)

    if entity_results is None:
        parser.exit(1, fill('Could not resolve \"' + args.path + '\" to a name or ID'), + '\n')

    for result in entity_results:
        try:
            dxpy.DXHTTPRequest('/' + result['id'] + '/setVisibility',
                               {"hidden": (args.visibility == 'hidden')})
        except dxpy.DXAPIError as details:
            print fill(unicode(details))
            had_error = True
    if had_error:
        parser.exit(1)

def get_details(args):
    # Attempt to resolve name
    project, folderpath, entity_result = try_call(resolve_existing_path,
                                                  args.path, expected='entity')

    if entity_result is None:
        parser.exit(1, fill('Could not resolve \"' + args.path + '\" to a name or ID') + '\n')

    try:
        print json.dumps(dxpy.DXHTTPRequest('/' + entity_result['id'] + '/getDetails', {}), indent=4)
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(unicode(details)) + '\n')

def set_details(args):
    had_error = False
    # Attempt to resolve name
    project, folderpath, entity_results = try_call(resolve_existing_path,
                                                   args.path, expected='entity',
                                                   allow_mult=True)

    if entity_results is None:
        parser.exit(1, fill('Could not resolve \"' + args.path + '\" to a name or ID') + '\n')

    try:
        args.details = json.loads(args.details)
    except ValueError:
        parser.exit(1, 'Error: details could not be parsed as JSON')

    for result in entity_results:
        try:
            dxpy.DXHTTPRequest('/' + result['id'] + '/setDetails',
                               args.details)
        except dxpy.DXAPIError as details:
            print(fill(unicode(details)))
            had_error = True
    if had_error:
        parser.exit(1)

def add_types(args):
    had_error = False
    # Attempt to resolve name
    project, folderpath, entity_results = try_call(resolve_existing_path,
                                                   args.path,
                                                   expected='entity',
                                                   allow_mult=True)

    if entity_results is None:
        parser.exit(1, fill('Could not resolve \"' + args.path + '\" to a name or ID') + '\n')

    for result in entity_results:
        try:
            dxpy.DXHTTPRequest('/' + result['id'] + '/addTypes',
                               {"types": args.types})
        except dxpy.DXAPIError as details:
            print fill(unicode(details))
            had_error = True
    if had_error:
        parser.exit(1)

def remove_types(args):
    had_error = False
    # Attempt to resolve name
    project, folderpath, entity_results = try_call(resolve_existing_path,
                                                   args.path,
                                                   expected='entity',
                                                   allow_mult=True)

    if entity_results is None:
        parser.exit(1, fill('Could not resolve \"' + args.path + '\" to a name or ID') + '\n')

    for result in entity_results:
        try:
            dxpy.DXHTTPRequest('/' + result['id'] + '/removeTypes',
                               {"types": args.types})
        except dxpy.DXAPIError as details:
            print fill(unicode(details))
            had_error = True
    if had_error:
        parser.exit(1)

def add_tags(args):
    had_error = False
    # Attempt to resolve name
    project, folderpath, entity_results = try_call(resolve_existing_path,
                                                   args.path,
                                                   expected='entity',
                                                   allow_mult=True)

    if entity_results is None:
        parser.exit(1, fill('Could not resolve \"' + args.path + '\" to a name or ID') + '\n')

    for result in entity_results:
        try:
            dxpy.DXHTTPRequest('/' + result['id'] + '/addTags',
                               {"project": project,
                                "tags": args.tags})
        except BaseException as details:
            print fill(unicode(details))
            had_error = True
    if had_error:
        parser.exit(1)

def remove_tags(args):
    had_error = False
    # Attempt to resolve name
    project, folderpath, entity_results = try_call(resolve_existing_path,
                                                   args.path,
                                                   expected='entity',
                                                   allow_mult=True)

    if entity_results is None:
        parser.exit(1, 'Could not resolve \"' + args.path + '\" to a name or ID\n')

    for result in entity_results:
        try:
            dxpy.DXHTTPRequest('/' + result['id'] + '/removeTags',
                               {"project": project,
                                "tags": args.tags})
        except BaseException as details:
            print fill(unicode(details))
            had_error = True
    if had_error:
        parser.exit(1)

def rename(args):
    had_error = False
    # Attempt to resolve name
    project, folderpath, entity_results = try_call(resolve_existing_path,
                                                   args.path,
                                                   expected='entity',
                                                   allow_mult=True)

    if entity_results is None and not is_container_id(args.path):
        if project is None:
            parser.exit(1, 'Could not resolve \"' + args.path + '\" to a name or ID\n')
        elif folderpath != None and folderpath != '/':
            parser.exit(1,
                        'Could not resolve \"' + args.path + \
                            '''\" to an existing data object or folder; if you
were attempting to refer to a project, append a colon ":" to indicate that it
is a project.\n''')

    if entity_results is not None:
        for result in entity_results:
            try:
                dxpy.DXHTTPRequest('/' + result['id'] + '/rename',
                                   {"project": project,
                                    "name": args.name})
            except BaseException as details:
                print fill(unicode(details))
                had_error = True
        if had_error:
            parser.exit(1)
    elif not project.startswith('project-'):
        parser.exit(1, 'Cannot rename a non-project data container\n')
    else:
        try:
            dxpy.DXHTTPRequest('/' + project + '/update',
                               {"name": args.name})
        except dxpy.DXAPIError as details:
            parser.exit(1, fill(unicode(details)) + '\n')

def set_properties(args):
    had_error = False
    # Attempt to resolve name
    project, folderpath, entity_results = try_call(resolve_existing_path,
                                                   args.path,
                                                   expected='entity',
                                                   allow_mult=True)

    if entity_results is None and project is None:
        parser.exit(1, 'Could not resolve \"' + args.path + '\" to a name or ID\n')

    properties = get_properties_from_args(args.properties)
    if entity_results is not None:
        for result in entity_results:
            try:
                dxpy.DXHTTPRequest('/' + result['id'] + '/setProperties',
                                   {"project": project,
                                    "properties": properties})
            except BaseException as details:
                print fill(unicode(details))
                had_error = True
        if had_error:
            parser.exit(1)
    elif not project.startswith('project-'):
        parser.exit(1, 'Cannot set properties on a non-project data container\n')
    else:
        try:
            dxpy.DXHTTPRequest('/' + project + '/setProperties',
                               {"properties": properties})
        except dxpy.DXAPIError as details:
            parser.exit(1, fill(unicode(details)) + '\n')

def unset_properties(args):
    had_error = False
    # Attempt to resolve name
    project, folderpath, entity_results = try_call(resolve_existing_path,
                                                   args.path,
                                                   expected='entity',
                                                   allow_mult=True)

    if entity_results is None and project is None:
        parser.exit(1, 'Could not resolve \"' + args.path + '\" to a name or ID\n')

    properties = {}
    for prop in args.properties:
        properties[prop] = None
    if entity_results is not None:
        for result in entity_results:
            try:
                dxpy.DXHTTPRequest('/' + result['id'] + '/setProperties',
                                   {"project": project,
                                    "properties": properties})
            except BaseException as details:
                print fill(unicode(details))
                had_error = True
        if had_error:
            parser.exit(1)
    elif not project.startswith('project-'):
        parser.exit(1, 'Cannot unset properties on a non-project data container\n')
    else:
        try:
            dxpy.DXHTTPRequest('/' + project + '/setProperties',
                               {"properties": properties})
        except dxpy.DXAPIError as details:
            parser.exit(1, fill(unicode(details)) + '\n')

def get(args):
    # Attempt to resolve name
    project, folderpath, entity_result = try_call(resolve_existing_path,
                                                  args.path, expected='entity')

    if entity_result is None:
        parser.exit(1, fill('Could not resolve ' + args.path + ' to a data object') + '\n')

    filename = args.output
    if filename is None:
        filename = entity_result['describe']['name'].replace('/', '%2F')

    if entity_result['describe']['class'] == 'file':
        if args.stdout:
            try:
                dxfile = dxpy.DXFile(entity_result['id'])
                for line in dxfile:
                    print line
            except dxpy.DXAPIError as details:
                parser.exit(1, fill(unicode(details)) + '\n')
        else:
            if not args.overwrite and os.path.exists(filename):
                parser.exit(1, fill('Error: path \"' + filename + '\" already exists but -f/--overwrite was not set') + '\n')
            try:
                dxpy.download_dxfile(entity_result['id'], filename)
            except dxpy.DXAPIError as details:
                parser.exit(1, fill(unicode(details)) + '\n')
    elif entity_result['describe']['class'] in ['gtable', 'table']:
        if not args.tsv and not args.csv and not args.vcf:
            args.tsv = True
        dxtable = dxpy.get_handler(entity_result['id'])
        if args.tsv or args.csv:
            delimiter = '\t' if args.tsv else ','
            if args.stdout:
                writer = csv.writer(sys.stdout, delimiter=delimiter)
            else:
                if args.output is None:
                    filename += '.tsv' if args.tsv else '.csv'
                if not args.overwrite and os.path.exists(filename):
                    parser.exit(1, fill('Error: path \"' + filename + '\" already exists but -f/--overwrite was not set') + '\n')
                writer = csv.writer(open(filename, 'wb'),
                                    delimiter=delimiter)
            if not args.no_header:
                writer.writerow(([] if args.no_rowid else ['__id__']) + [col['name'] for col in dxtable.describe()['columns']])

            for row in dxtable:
                writer.writerow([unicode(item).encode('utf-8') for item in row[1 if args.no_rowid else 0:]])
        else:
            parser.exit(1, 'Not implemented yet\n')
    elif entity_result['describe']['class'] == 'record':
        try:
            details = dxpy.DXHTTPRequest('/' + entity_result['id'] + '/getDetails',
                                         {})
        except BaseException as details:
            parser.exit(1, fill(unicode(details)) + '\n')
        if args.stdout:
            print json.dumps(details, indent=4)
        else:
            if args.output is None:
                filename += '.json'
            if not args.overwrite and os.path.exists(filename):
                parser.exit(1, fill('Error: path \"' + filename + '\" already exists but -f/--overwrite was not set') + '\n')
            try:
                with open(filename, 'w') as fd:
                    fd.write(json.dumps(details, indent=4))
            except BaseException as details:
                parser.exit(1, fill(unicode(details)) + '\n')
    elif entity_result['describe']['class'] == 'applet':
        dxapplet = dxpy.DXApplet(entity_result['id'])
        try:
            resp = dxapplet.get()
            if 'run' in resp:
                run_spec = resp['run']
            elif 'runSpec' in resp:
                run_spec = resp['runSpec']
            else:
                raise Exception('No run specification found')
        except BaseExceptions as details:
            parser.exit(1, fill(unicode(details)) + '\n')
        if args.stdout:
            print run_spec['code']
            return
        elif args.output is None:
            if run_spec['interpreter'] == 'python2.7':
                filename += '.py'
            elif run_spec['interpreter'] == 'v8cgi':
                filename += '.js'
            elif run_spec['interpreter'] == 'bash':
                filename += '.sh'
        if not args.overwrite and os.path.exists(filename):
            parser.exit(1, fill('Error: path \"' + filename + '\" already exists but -f/--overwrite was not set') + '\n')
        try:
            with open(filename, 'w') as fd:
                fd.write(run_spec['code'])
        except BaseException as details:
            parser.exit(1, fill(unicode(details)) + '\n')
    else:
        parser.exit(1, 'Error: The given object is of class ' + entity_result['describe']['class'] + ' but an object of class record, file, gtable, table, or applet was expected\n')

def cat(args):
    for path in args.path:
        get_args = parser.parse_args(['get', '--stdout', path])
        get(get_args)

def head(args):
    # Attempt to resolve name
    project, folderpath, entity_result = try_call(resolve_existing_path,
                                                  args.path, expected='entity')
    if entity_result is None:
        parser.exit(1, fill('Could not resolve ' + args.path + ' to a data object') + '\n')
    if not entity_result['describe']['class'] in ['gtable', 'file', 'table']:
        parser.exit(1, 'Error: The given object is of class ' + entity_result['describe']['class'] + ' but an object of class gtable, file, or table was expected\n')

    handler = dxpy.get_handler(entity_result['id'])

    counter = 0
    if args.lines > 0:
        try:
            if handler._class == 'file':
                handler._bufsize = 1024*32;
                for line in handler:
                    print line
                    counter += 1
                    if counter == args.lines:
                        break
            else:
                table_text, table_rows, table_cols = format_table(list(handler.iterate_rows(end=args.lines)),
                                                                  column_specs = entity_result['describe']['columns'],
                                                                  report_dimensions=True,
                                                                  max_col_width=args.max_col_width)
                if sys.stdout.isatty():
                    if tty_rows <= table_rows or tty_cols <= table_cols:
                        try:
                            pipe = os.popen('less -RS', 'w')
                            pipe.write(table_text.encode('utf-8'))
                            pipe.close()
                            return
                        except:
                            pass
                sys.stdout.write(table_text + '\n')
        except StopIteration:
            pass
        except BaseException as details:
            parser.exit(1, fill(unicode(details)) + '\n')

def upload(args):
    hidden = (args.visibility == 'hidden')
    properties = get_properties_from_args(args.properties)
    details = None
    if args.details is not None:
        try:
            details = json.loads(args.details)
        except:
            parser.exit(1, 'Error: details could not be parsed as JSON\n')
    if args.name is None:
        args.name = os.path.basename(args.filename)

    # if args.folder is None and (args.project is None or args.project == dxpy.WORKSPACE_ID):
    #     args.folder = os.environ.get('DX_CLI_WD', '/')

    try:
        dxfile = dxpy.upload_local_file(args.filename,
                                        name=args.name,
                                        tags=args.tags,
                                        types=args.types,
                                        hidden=hidden,
                                        project=args.project,
                                        properties=properties,
                                        details=details,
                                        folder=args.folder,
                                        parents=args.parents)
        if args.wait:
            dxfile._wait_on_close()
        if args.brief:
            print dxfile.get_id()
        else:
            print_desc(dxfile.describe(incl_properties=True, incl_details=True))
    except BaseException as details:
        parser.exit(1, fill(unicode(details)) + '\n')

def parse_item(item, item_type):
    if item_type == 'string':
        return item
    elif item_type == 'int':
        return int(item)
    elif item_type == 'float':
        return float(item)
    elif item_type == 'boolean':
        if item == '0' or item.lower().startswith('f'):
            return False
        else:
            return True
    else:
        parser.exit(1, 'Unrecognized column type: ' + item_type + '\n')

def dximport(args):
    hidden = (args.visibility == 'hidden')
    properties = get_properties_from_args(args.properties)
    details = None
    if args.details is not None:
        try:
            details = json.loads(args.details)
        except:
            parser.exit(1, 'Error: details could not be parsed as JSON\n')
    if args.filename == '-':
        fd = sys.stdin
    else:
        try:
            fd = open(args.filename, 'rb')
        except:
            parser.exit(1, fill(unicode('Could not open ' + args.filename + ' for reading')) + '\n')
        if args.name is None:
            args.name = os.path.basename(args.filename)

    if not args.vcf:
        firstrow = fd.readline()

        if args.csv:
            delimiter = ','
            dialect = 'excel'
        elif args.tsv:
            delimiter = '\t'
            dialect = 'excel'
        else:
            # Try to sniff the file format
            dialect = csv.Sniffer().sniff(firstrow)
            delimiter = dialect.delimiter
        firstrow_reader = csv.reader([firstrow], dialect=dialect,
                                     delimiter=delimiter)
        firstrow_data = firstrow_reader.next()
        reader = csv.reader(fd, dialect=dialect,
                            delimiter=delimiter)

        column_specs = []
        types = []
        if args.column_names is not None:
            specs = args.column_names.split(",")
        else:
            specs = firstrow_data
        for spec in specs:
            if ':' in spec:
                col_type = spec[spec.find(':') + 1:]
                column_specs.append({'name': spec[:spec.find(':')],
                                     'type': col_type})
                if 'int' in col_type:
                    types.append('int')
                elif col_type == 'boolean':
                    types.append('boolean')
                elif col_type in ['float', 'double']:
                    types.append('float')
                elif col_type == 'string':
                    types.append('string')
                else:
                    parser.exit(1, 'Unrecognized column type: ' + col_type + '\n')
            else:
                column_specs.append({'name': spec,
                                     'type': 'string'})
                types.append('string')
        try:
            dxgtable = dxpy.new_dxgtable(project=args.project, name=args.name,
                                         tags=args.tags, types=args.types, 
                                         hidden=hidden, properties=properties,
                                         details=details,
                                         folder=args.folder,
                                         parents=args.parents,
                                         columns=column_specs)
            if args.column_names is not None:
                dxgtable.add_row([ parse_item(firstrow_data[i], types[i]) for i in range(len(types))])
            for row in reader:
                dxgtable.add_row([ parse_item(row[i], types[i]) for i in range(len(types))])
            dxgtable.close(block=args.wait)
            if args.brief:
                print dxgtable.get_id()
            else:
                print_desc(dxgtable.describe(incl_properties=True, incl_details=True))
        except BaseException as details:
            parser.exit(1, fill(unicode(details)) + '\n')
    else:
        parser.exit(1, 'Not yet implemented\n')

def export_fastq(args):
    from dxpy.scripts import dx_reads_to_fastq
    sys.argv = [sys.argv[0]] + args.exporter_args
    dx_reads_to_fastq.main()

def export_sam(args):
    from dxpy.scripts import dx_mappings_to_sam
    sys.argv = [sys.argv[0]] + args.exporter_args
    dx_mappings_to_sam.main()

exporters = {
    "fastq": export_fastq,
    "sam": export_sam
}

def export(args):
    if args.format.lower() not in exporters:
        parser.exit(1, fill('Unsupported format: \"' + args.format + '\".  For a list of supported formats, run "dx help export"') + '\n')
    exporters[args.format.lower()](args)

def gtable_get(args):
    # Attempt to resolve name
    project, folderpath, entity_result = try_call(resolve_existing_path,
                                                  args.path, expected='entity')

    if entity_result is None or entity_result['describe']['class'] != 'gtable':
        parser.exit(1, 'Could not resolve \"' + args.path + '\" to a gtable object\n')

    gri_query = None
    if args.gri is not None:
        gri_query = dxpy.DXGTable.genomic_range_query(args.gri[0],
                                                      int(args.gri[1]),
                                                      int(args.gri[2]),
                                                      args.gri_mode,
                                                      args.gri_name)
    try:
        result = dxpy.DXGTable(entity_result['id']).get_rows(query=gri_query,
                                                             starting=args.starting,
                                                             limit=args.limit)
        if args.json:
            print json.dumps(result, indent=4)
            return
        if result["next"] is not None:
            print "Use as STARTING to continue query: " + str(result["next"])
        print "# retrieved rows: " + str(result["length"])
        for row in result["data"]:
            print json.dumps(row, indent=4)
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(unicode(details)) + '\n')

def find_jobs(args):
    get_output_flag(args)
    try:
        describe = {"io": False} if args.summary else args.verbose
        results = list(dxpy.find_jobs(launched_by=args.user,
                                      applet=args.applet,
                                      project=args.project,
                                      state=args.state,
                                      origin_job=args.origin,
                                      parent_job=args.parent,
                                      describe=describe,
                                      created_after=args.created_after,
                                      created_before=args.created_before))

        if args.json:
            print json.dumps(results, indent=4)
            return

        if args.brief:
            for result in results:
                print result['id']
            return
        else:
            job_ids = {}
            job_children = {}
            origin_jobs = []
            for i in range(len(results)):
                job_ids[results[i]['id']] = i
                parent = results[i]['describe']['parentJob']
                if parent is None:
                    origin_jobs.append(i)
                elif parent in job_children:
                    job_children[parent].append(i)
                else:
                    job_children[parent] = [i]

            def print_children(parent_id, num_tabs):
                print_string = ""
                for j in range(num_tabs):
                    print_string += '\t'
                if 'name' in results[job_ids[parent_id]]['describe'] and results[job_ids[parent_id]]['describe']['name'] is not None:
                    print_string += results[job_ids[parent_id]]['describe']['name'] + ' '
                        
                print_string += parent_id + ' ' + \
                    str(datetime.datetime.fromtimestamp(results[job_ids[parent_id]]['describe']['created']/1000)) + \
                    ' ('
                state = results[ job_ids[parent_id] ]['describe']['state']
                print_string += JOB_STATES(state)
                print_string += ')'
                print print_string

                if parent_id in job_children:
                    for child in job_children[parent_id]:
                        print_children(results[child]['id'], num_tabs + 1)

            n = 0
            for origin_job in origin_jobs:
                orig_id = results[origin_job]["id"]
                print_children(orig_id, 0)
                n += 1
                if args.num_results is not None and n >= args.num_results:
                    break
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(unicode(details)) + '\n')

def find_data(args):
    get_output_flag(args)
    properties = get_properties_from_args(args.properties)
    try:
        if args.no_glob or args.brief or args.name is None:
            args.glob_name = None
        else:
            # Stash the name and filter it on the client side.
            # Warning: client-side globbing is a transitional feature pending server-side pattern matching
            args.glob_name = args.name
            args.name = None

        results = list(dxpy.find_data_objects(classname=args.classname,
                                              state=args.state,
                                              visibility=args.visibility,
                                              properties=properties,
                                              name=args.name,
                                              typename=args.type,
                                              tag=args.tag, link=args.link,
                                              project=args.project,
                                              folder=args.folder,
                                              recurse=args.recurse,
                                              modified_after=args.mod_after,
                                              modified_before=args.mod_before,
                                              created_after=args.created_after,
                                              created_before=args.created_before,
                                              describe=(not args.brief)))

        if args.glob_name:
            import fnmatch
            results = [r for r in results if fnmatch.fnmatch(r['describe']['name'], args.glob_name)]

        if args.json:
            print json.dumps(results, indent=4)
            return
        if args.brief:
            for result in results:
                print result['id']
        else:
            for result in results:
                if args.verbose:
                    print ""
                    print_data_obj_desc(result["describe"])
                else:
                    print_ls_l_desc(result["describe"], include_folder=True)
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(unicode(details)) + '\n')

def find_projects(args):
    get_output_flag(args)
    try:
        results = list(dxpy.find_projects(name=args.name, level=args.level,
                                          describe=(not args.brief),
                                          public=args.public))
        if args.json:
            print json.dumps(results, indent=4)
            return
        if args.brief:
            for result in results:
                print result['id']
            return
        if args.summary or args.verbose:
            for result in results:
                cached_project_names[result['describe']['name']] = result['id']
                print result["id"] + " : " + result['describe']['name'] + ' (' + result["level"] + ')'
        print ""
        return map(lambda result: result["id"], results)
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(unicode(details)) + '\n')

def find_apps(args):
    get_output_flag(args)
    try:
        results = list(dxpy.find_apps(name=args.name, category=args.category,
                                      all_versions=args.all,
                                      published=(not args.unpublished),
                                      billed_to=args.billed_to,
                                      created_by=args.creator,
                                      developer=args.developer,
                                      created_after=args.created_after,
                                      created_before=args.created_before,
                                      modified_after=args.mod_after,
                                      modified_before=args.mod_before,
                                      describe=True))

        if args.installed:
            results = filter(lambda result: result['describe']['installed'],
                             results)

        if args.brief:
            results = map(lambda result: {"id": result['id']},
                          results)

        if args.json:
            print json.dumps(results, indent=4)
            return
        if args.brief:
            for result in results:
                print result['id']
        elif args.summary:
            for result in results:
                print result["describe"]["name"] + " (v" + result["describe"]["version"] + ")"
        else:
            for result in results:
                print result["id"] + " " + result["describe"]["name"] + ' v' + result['describe']['version'] + (" (published)" if result["describe"]["published"] > 0 else " (unpublished)")
    except BaseException as details:
        parser.exit(1, fill(unicode(details)) + '\n')

def close(args):
    # Attempt to resolve name
    project, folderpath, entity_results = try_call(resolve_existing_path,
                                                   args.path,
                                                   expected='entity',
                                                   allow_mult=True)

    if entity_results is None:
        parser.exit(1, 'Could not resolve \"' + args.path + '\" to a name or ID\n')

    handlers = []
    for result in entity_results:
        try:
            obj = dxpy.get_handler(result['id'], project=project)
            obj.close()
            handlers.append(obj)
        except dxpy.DXAPIError as details:
            print fill(unicode(details))
    if args.wait:
        for handler in handlers:
            handler._wait_on_close()

def build(args):
    '''
    FIXME: Warning: a limitation/bug in argparse requires the first argument in args.builder_args to be positional.
    This means that despite the usage that dx-build-app prints (dx-build-app [options] build_dir),
    when called through dx, it must instead be called as "dx build build_dir [options]".
    '''
    from dxpy.scripts import dx_build_app
    sys.argv = [sys.argv[0]] + args.builder_args
    dx_build_app.main()

def install(args):
    app_desc = get_app_from_path(args.app)
    if app_desc is None:
        parser.exit(1, 'Could not find the app')
    else:
        try:
            dxpy.DXHTTPRequest('/' + app_desc['id'] + '/install', {})
            print 'Installed the ' + app_desc['name'] + ' app'
        except BaseException as details:
            parser.exit(1, fill(unicode(details)) + '\n')

def uninstall(args):
    app_desc = get_app_from_path(args.app)
    if app_desc is None:
        parser.exit(1, 'Could not find the app')
    else:
        try:
            dxpy.DXHTTPRequest('/' + app_desc['id'] + '/uninstall', {})
            print 'Uninstalled the ' + app_desc['name'] + ' app'
        except BaseException as details:
            parser.exit(1, fill(unicode(details)) + '\n')

def get_exec_inputs(inputs):
    required_inputs = []
    optional_inputs = []
    for input_spec in inputs:
        if "default" in input_spec or ("optional" in input_spec and input_spec["optional"] == True):
            optional_inputs.append(input_spec)
        else:
            required_inputs.append(input_spec)
    return required_inputs, optional_inputs

def parse_bool(string):
    if 'true'.startswith(string.lower()) or string == '1':
        return True
    elif 'false'.startswith(string.lower()) or string == '0':
        return False
    else:
        raise ValueError('Could not resolve \"' + string +  '\" to a boolean')

def parse_obj(string, klass):
    if string == '':
        raise ValueError('Error: Nonempty string cannot be resolved')
    project, path, entity_result = try_call(resolve_existing_path, string)
    if entity_result is None:
        raise TypeError('Could not resolve \"' + string + '\" to a name or ID')
    if not entity_result['describe']['class'] == klass:
        raise TypeError('Error: The given object is of class ' + entity_result['describe']['class'] + ' but an object of class ' + klass + ' was expected.')
    return {'$dnanexus_link': entity_result['id']}

dx_data_classes = ['record', 'gtable', 'file', 'applet', 'table']

parse_input = {'boolean': parse_bool,
               'string': (lambda string: string),
               'float': (lambda string: float(string)),
               'int': (lambda string: int(string)),
               'hash': (lambda string: json.loads(string)),
               'record': (lambda string: parse_obj(string, 'record')),
               'gtable': (lambda string: parse_obj(string, 'gtable')),
               'file': (lambda string: parse_obj(string, 'file')),
               'applet': (lambda string: parse_obj(string, 'applet')),
               'job': (lambda string: {'$dnanexus_link': string}),
               'app': (lambda string: {'$dnanexus_link': string}),
               'table': (lambda string: parse_obj(string, 'table'))}

def get_input_array(param_desc):
    in_class = param_desc['class'][6:]
    typespec = param_desc.get('type', None)
    input_array = []
    print '\nEnter list of inputs (^D or empty string to finish) of class ' + BOLD() + in_class + ENDC() + ' for ' + get_io_desc(param_desc, include_class=False) + ':\n'
    try:
        if in_class in dx_data_classes:
            readline.set_completer(DXPathCompleter(classes=[in_class],
                                                   typespec=typespec))
        else:
            readline.set_completer()
    except:
        pass
    try:
        while True:
            user_input = raw_input(param_desc['name'] + '[' + str(len(input_array)) + "]: ")
            user_input = shlex.split(user_input)
            if len(user_input) > 1:
                print fill('Error: more than one argument given.  Please quote your entire input or escape your whitespace with a backslash \'\\\'.')
                continue
            elif len(user_input) == 0:
                return input_array
            try:
                input_array.append(parse_input[in_class](user_input[0]))
            except ValueError as details:
                print fill('Error occurred when parsing for class ' + in_class + ': ' + unicode(details))
                continue
            except TypeError as details:
                print fill('Error occurred when parsing for class ' + in_class + ': ' + unicode(details))
                continue
    except EOFError:
        return input_array
    except BaseException as details:
        parser.exit(1, fill(unicode(details)) + '\n')

def get_input_single(param_desc):
    in_class = param_desc['class']
    typespec = param_desc.get('type', None)
    print '\nEnter input of class ' + BOLD() + in_class + ENDC() + ' for ' + get_io_desc(param_desc, include_class=False, show_opt=False) +  ' (press Tab twice to see choices):'

    try:
        if in_class in dx_data_classes:
            readline.set_completer(DXPathCompleter(classes=[in_class],
                                                   typespec=typespec))
        else:
            readline.set_completer()
    except:
        pass
    try:
        while True:
            user_input = raw_input(param_desc['name'] + ': ')
            user_input = shlex.split(user_input)
            if len(user_input) > 1:
                print fill('Error: more than one argument given.  Please quote your entire input or escape your whitespace with a backslash \'\\\'.')
                continue
            elif len(user_input) == 0:
                user_input = ['']
            try:
                value = parse_input[in_class](user_input[0])
            except ValueError as details:
                print fill('Error occurred when parsing for class ' + in_class + ': ' + unicode(details))
                continue
            except TypeError as details:
                print fill('Error occurred when parsing for class ' + in_class + ': ' + unicode(details))
                continue
            return value
    except EOFError:
        parser.exit(1, '\n')
    except KeyboardInterrupt:
        parser.exit(1, '\n')
    except BaseException as details:
        parser.exit(1, fill(unicode(details)) + '\n')

def get_input(input_hash, param):
    if param['class'].startswith('array:'):
        input_hash[param['name']] = get_input_array(param)
    else:
        input_hash[param['name']] = get_input_single(param)

def get_optional_inputs(input_hash, optional_inputs):
    names = map(lambda spec: spec['name'], optional_inputs)
    while True:
        print '\nSelect an optional parameter to set by its # (^D or empty string to finish):\n'
        for i in range(len(optional_inputs)):
            opt_str = ' [' + str(i) + '] ' + \
                get_io_desc(optional_inputs[i], show_opt=False)
            if optional_inputs[i]['name'] in input_hash:
                opt_str += ' [=' + GREEN()
                opt_str += json.dumps(input_hash[optional_inputs[i]['name']])
                opt_str += ENDC() + ']'
            print opt_str
        print ""
        try:
            while True:
                selected = raw_input('Optional param #: ')
                if selected == '':
                    return
                try:
                    opt_num = int(selected)
                    if opt_num < 0 or opt_num >= len(optional_inputs):
                        raise ValueError('Error: Selection is out of range')
                    break
                except ValueError as details:
                    print unicode(details)
                    continue
        except EOFError:
            return
        except BaseException as details:
            parser.exit(1, fill(unicode(details)) + '\n')
        get_input(input_hash, optional_inputs[opt_num])

def add_input_to_json(inputs, input_json, input_specs):
    '''
    :param inputs: list of [name, value] lists
    :param input_json: input JSON being built
    :param input_specs: list of all input specs
    '''

    if input_specs is not None:
        # Input spec is provided.  Throw errors if name is not found,
        # and respect the "array" class.
        names = map(lambda spec: spec['name'], input_specs)
        found_duplicates = False
        for i in inputs:
            try:
                input_index = names.index(i[0])
            except:
                parser.exit(1, fill('Input field called ' + i[0] + ' was not found in the input spec') + '\n')

            input_class = input_specs[input_index]['class']
            if input_class.startswith('array:'):
                input_class = input_class[6:]
                is_array = True
            else:
                is_array = False

            try:
                parsed = parse_input[input_class](i[1])
            except BaseException as details:
                parser.exit(1, fill(unicode(details)) + '\n')

            if i[0] not in input_json:
                if is_array:
                    input_json[i[0]] = [parsed]
                else:
                    input_json[i[0]] = parsed
            elif is_array:
                input_json[i[0]].append(parsed)
            else:
                 parser.exit(1, fill('Error: Found duplicate input field names for an input that does not expect an array of inputs') + '\n')

    else:
        # No input spec.  Make them all lists and then un-list them if
        # there's only one element at the end.  (Since arbitrary JSON
        # is valid input.)
        for i in inputs:
            try:
                parsed = json.loads(i[1])
                if i[0] not in input_json:
                    input_json[i[0]] = [parsed]
                else:
                    input_json[i[0]].append(parsed)
            except:
                # Not valid JSON, so resolve it as a name
                project, folderpath, entity_result = try_call(resolve_existing_path,
                                                              i[1],
                                                              expected='entity')
                if entity_result is None:
                    parser.exit(1, 'Could not resolve ' + i[1] + ' to a value or object ID')
                if i[0] not in input_json:
                    input_json[i[0]] = [{"$dnanexus_link": entity_result['id']}]
                else:
                    input_json[i[0]].append({"$dnanexus_link": entity_result['id']})
        for key in input_json:
            if len(input_json[key]) == 1:
                input_json[key] = input_json[key][0]

def run(args):
    get_output_flag(args)
    handler = None
    desc = None
    if args.alias is None:
        # Attempt to resolve name (and only look for applets)
        try:
            project, folderpath, entity_results = resolve_existing_path(args.path,
                                                                        expected='entity',
                                                                        ask_to_resolve=False,
                                                                        expected_classes=['applet'])
        except:
            entity_results = None
        app_desc = get_app_from_path(args.path)
        if entity_results is not None and len(entity_results) == 1 and app_desc is None:
            handler = dxpy.DXApplet(entity_results[0]['id'])
            desc = entity_results[0]['describe']
        elif entity_results is None and app_desc is not None:
            handler = dxpy.DXApp(dxid=app_desc['id'])
            desc = app_desc
        elif entity_results is not None and app_desc is not None:
            if not sys.stdout.isatty():
                parser.exit(1, 'Found multiple executables with the path ' + args.path + '\n')
            print 'Found multiple executables with the path ' + args.path
            choice = try_call(pick, map(lambda result: get_ls_l_desc(result['describe']),
                                        entity_results) + ['app-' + app_desc['name'] + ', version ' + app_desc['version']])
            if choice < len(entity_results):
                handler = dxpy.get_handler(entity_results[choice]['id'], project)
                desc = entity_results[choice]['describe']
            else:
                handler = dxpy.DXApp(dxid=app_desc['id'])
                desc = app_desc
        else:
            parser.exit(1, "No matches found for " + args.path + '\n')
    else:
        if args.path.startswith('app-'):
            args.path = args.path[4:]
        handler = dxpy.DXApp(name=args.path, alias=args.alias)
        desc = handler.describe()

    if args.folder is None:
        dest_proj = dxpy.WORKSPACE_ID
        dest_path = os.environ.get('DX_CLI_WD', '/').decode('utf-8')
    else:
        dest_proj, dest_path, none = try_call(resolve_existing_path,
                                              args.folder,
                                              expected='folder')

    input_json = {}
    if 'inputSpec' in desc:
        required_inputs, optional_inputs = get_exec_inputs(desc["inputSpec"])
    elif 'inputs' in desc:
        required_inputs, optional_inputs = get_exec_inputs(desc["inputs"])
    else:
        required_inputs, optional_inputs = None, None

    if args.input_json is not None:
        try:
            input_json = json.loads(args.input_json)
        except:
            parser.exit(1, 'Error: input could not be parsed as JSON\n')
    elif args.filename is not None:
        try:
            fd = open(args.filename, 'r')
            data = fd.read()
            fd.close()
        except BaseException as details:
            parser.exit(1, fill(unicode(details)) + '\n')
        try:
            input_json = json.loads(data)
        except:
            parser.exit(1, 'Error: file could not be parsed as JSON\n')
    elif args.stdin:
        try:
            input_json = json.loads(raw_input('Input JSON > '))
        except BaseException as details:
            parser.exit(1, fill(unicode(details)) + '\n')
    elif args.input is not None:
        input_inputs = []
        try:
            for keyeqval in args.input:
                name, value = split_unescaped('=', keyeqval)
                input_inputs.append([name, value])
        except:
            parser.exit(1, fill('An input was found that did not conform to the syntax') + '\n -i<input_name>=<input value>\n')
        add_input_to_json(input_inputs, input_json,
                          (required_inputs + optional_inputs) if required_inputs is not None else None)

    elif required_inputs is not None and (len(required_inputs) > 0 or len(optional_inputs) > 0):
        if sys.stdout.isatty():
            print 'No input given.  Entering interactive mode for input selection.'
            try:
                # If running from the command-line (not in the shell),
                # bring up the tab-completer
                import rlcompleter
                readline.parse_and_bind("tab: complete")

                readline.set_completer_delims("")

                readline.write_history_file(os.path.expanduser('~/.dnanexus_config/.dx_history'))
                readline.clear_history()
                readline.set_completer()
            except:
                pass

            # Select input interactively
            if len(required_inputs) > 0:
                for param in required_inputs:
                    get_input(input_json, param)
            if len(optional_inputs) > 0:
                get_optional_inputs(input_json, optional_inputs)

            # Set no completer
            try:
                readline.set_completer()
                readline.clear_history()
            except:
                pass
    elif required_inputs is not None:
        if not args.brief:
            print fill('No input given, and applet/app takes in no inputs.  Skipping interactive mode for input selection.')
    else:
        if not args.brief:
            print fill('No input given, and applet has no input specification.  Skipping interactive mode for input selection (no input parameters will be set).  To provide input parameters anyway, please specify them explicitly using one of the input flags.')

    if not args.brief:
        print ''
        print 'Using input JSON:'
        print json.dumps(input_json, indent=4)
        print ''

    # Ask for confirmation if a tty and if input was not given as a
    # single JSON.
    if args.confirm and (args.input_json is None and args.filename is None and not args.stdin and sys.stdout.isatty()):
        try:
            value = raw_input('Confirm running the applet/app with this input [Y/n]: ')
        except BaseException as details:
            parser.exit(1, fill(unicode(details)) + '\n')
        if value != '' and not value.lower().startswith('y'):
            parser.exit(0)

    if not args.brief:
        print fill("Calling " + handler.get_id() + " with output destination " + dest_proj + ":" + dest_path, subsequent_indent='  ') + '\n'
    try:
        dxjob = handler.run(input_json, project=dest_proj, folder=dest_path)
        if not args.brief:
            print "Job ID: " + dxjob.get_id()
        else:
            print dxjob.get_id()
        if args.wait:
            dxjob.wait_on_done()
        if args.watch:
            watch_args = parser.parse_args(['watch', dxjob.get_id()])
            watch(watch_args)
    except BaseException as details:
        parser.exit(1, fill(unicode(details)) + '\n')

def terminate(args):
    try:
        dxpy.api.jobTerminate(args.jobid)
    except BaseException as details:
        parser.exit(1, fill(unicode(details)) + '\n')

def shell(orig_args):
    if orig_args.filename is not None:
        try:
            with open(orig_args.filename, 'r') as script:
                for line in script:
                    args = parser.parse_args(shlex.split(line))
                    set_cli_colors(args)
                    args.func(args)
            exit(0)
        except BaseException as details:
            parser.exit(1, fill(unicode(details)))
    elif not sys.stdin.isatty():
        for line in sys.stdin.read().splitlines():
            if len(line) > 0:
                args = parser.parse_args(shlex.split(line))
                set_cli_colors(args)
                args.func(args)
        exit(0)

    if state['interactive']:
        return
    state['interactive'] = True

    # WARNING: Following two lines may not be platform-independent and
    # should be made so.
    try:
        import rlcompleter
        readline.parse_and_bind("tab: complete")

        readline.set_completer_delims("")

        readline.set_completer(DXCLICompleter())
    except:
        pass

    while True:
        # Reset the completer once we're done grabbing input
        try:
            if readline.get_completer() is None:
                readline.set_completer(DXCLICompleter())
                readline.clear_history()
                readline.read_history_file(os.path.expanduser('~/.dnanexus_config/.dx_history'))
        except:
            pass
        try:
            prompt = '> '
            pwd_str = get_pwd()
            if pwd_str is not None:
                prompt = pwd_str + prompt
            cmd = raw_input(prompt)
        except EOFError:
            print ""
            exit(0)
        except KeyboardInterrupt:
            print ""
            continue
        if cmd == '':
            continue
        try:
            args = parser.parse_args(shlex.split(cmd))
            set_cli_colors(args)
            args.func(args)
        except StopIteration:
            exit(0)
        except BaseException as details:
            if unicode(details) != '1' and unicode(details) != '0':
                print unicode(details) + '\n'

def watch(args):
    try:
        from dxpy.utils.job_log_client import DXJobLogStreamClient
        streaming_id = dxpy.api.jobStreamLog(args.jobid, {"numRecentMessages": args.num_recent_messages, "recurseJobs": not args.no_subjobs})['streamingId']
        response = dxpy.DXHTTPRequest('/socket.io/1/', '', jsonify_data=False, want_full_response=True)
        hskey = response.content.split(':')[0]
        ws_proto = "wss" if dxpy.APISERVER_PROTOCOL == "https" else "ws"
        server = "{proto}://{host}:{port}".format(proto=ws_proto, host=dxpy.APISERVER_HOST, port=dxpy.APISERVER_PORT)
        ws = DXJobLogStreamClient(server + '/socket.io/1/websocket/' + hskey)
        ws.set_dx_streaming_id(streaming_id)

        print "Watching job %s%s. Press Ctrl+C to stop." % (args.jobid, ("" if args.no_subjobs else " and sub-jobs"))
        ws.connect()
        while not ws.terminated:
            # See also https://dnanexus.jira.com/browse/PTFM-2692
            time.sleep(5)
    except KeyboardInterrupt:
        ws.close()

def print_help(args):
    if args.command is None:
        parser.print_help()
    elif args.command not in parser_map:
        parser.exit(1, 'Unrecognized command: ' + args.command + '\n')
    elif args.subcommand is None:
        parser_map[args.command].print_help()
    elif (args.command + ' ' + args.subcommand) not in parser_map:
        parser.exit(1, 'Unrecognized command and subcommand combination: ' + args.command + ' ' + args.subcommand + '\n')
    else:
        parser_map[args.command + ' ' + args.subcommand].print_help()

def exit_shell(args):
    if state['interactive']:
        raise StopIteration()

# TODO: Add a subcommand for clearing the cache

no_color_arg = argparse.ArgumentParser(add_help=False)
no_color_arg.add_argument('--color',
                          help='Set when color is used (auto=color is used when stdout is a TTY)',
                          choices=['off', 'on', 'auto'], default='auto')

json_arg = argparse.ArgumentParser(add_help=False)
json_arg.add_argument('--json', help='Display return value in JSON', action='store_true')

# Warning: client-side globbing is a transitional feature pending server-side pattern matching
no_glob_arg = argparse.ArgumentParser(add_help=False)
no_glob_arg.add_argument('--no-glob', help="Don't use pattern matching in names", action='store_true')

stdout_args = argparse.ArgumentParser(add_help=False)
stdout_args_gp = stdout_args.add_mutually_exclusive_group()
stdout_args_gp.add_argument('--brief', help='Display a brief version of the return value.  For most commands, prints a DNAnexus ID per line.', action='store_true')
stdout_args_gp.add_argument('--summary', help='Display summary output (default).', action='store_true')
stdout_args_gp.add_argument('--verbose', help='If available, displays extra verbose output',
                            action='store_true')

parser = argparse.ArgumentParser(description=DNANEXUS_LOGO() + ' Command-Line Client, API v1.0.0',
usage='dx subcommand [options]')
parser.add_argument('--version', action='version', version='dxclient 0.0.1')

subparsers = parser.add_subparsers()
subparsers.metavar = 'subcommand'

parser_shell = subparsers.add_parser('sh', help='DX shell',
                                     description='When run with no arguments, this command launches an interactive shell.  Otherwise, it will load the filename provided and interpret each nonempty line as a command to execute.  In both cases, the "dx" is omitted.', prog='dx sh')
parser_shell.add_argument('filename', help='File of dx commands to execute', nargs='?', default=None)
parser_shell.set_defaults(func=shell)
parser_map['sh'] = parser_shell

parser_help = subparsers.add_parser('help', help='Display help message', prog='dx help')
parser_help.add_argument('command', help='Display the help message for the given command', nargs='?', default=None)
parser_help.add_argument('subcommand', help='Display the help message for the given subcommand of the command', nargs='?', default=None)
parser_help.set_defaults(func=print_help)
parser_map['help'] = parser_help

parser_exit = subparsers.add_parser('exit', help='Exit out of the interactive shell', prog='dx exit')
parser_exit.set_defaults(func=exit_shell)
parser_map['exit'] = parser_exit

parser_setenv = subparsers.add_parser('setenv', help='Sets environment variables for communication with the API server',
                                      description='Sets environment variables for communication with the API server')
parser_setenv.add_argument('--noprojects', dest='projects', help='Do not print available projects', action='store_false')
parser_setenv.add_argument('--save', help='Save settings for future sessions.  Only one set of settings can be saved at a time.  Always set to true if login is run in a non-interactive session', action='store_true')
parser_setenv.add_argument('--current', help='Do not prompt for new values and just save current settings for future sessions.  Overrides --save to be true.', action='store_true')
parser_setenv.set_defaults(func=setenv)

parser_clearenv = subparsers.add_parser('clearenv', help='Clears all environment variables set by dx', prog='dx clearenv')
parser_clearenv.set_defaults(func=clearenv)
parser_map['clearenv'] = parser_clearenv

parser_env = subparsers.add_parser('env', help='Prints all environment variables set for the CLI', prog='dx env')
parser_env.add_argument('--bash', help='Prints a list of bash commands to export the environment variables', action='store_true')
parser_env.set_defaults(func=env)
parser_map['env'] = parser_env

parser_login = subparsers.add_parser('login', help='Log in and acquire credentials', description='Log in interactively and acquire credentials', prog='dx login')
parser_login.add_argument('--token', help='Authentication token to use')
parser_login.add_argument('--emtest', help='Log into emtest', action='store_true')
parser_login.add_argument('--host', help='Log into the given auth server host (port must also be given)')
parser_login.add_argument('--port', type=int, help='Log into the given auth server port (host must also be given)')
parser_login.add_argument('--noprojects', dest='projects', help='Do not print available projects', action='store_false')
parser_login.add_argument('--save', help='Save token and other environment variables for future sessions', action='store_true')
parser_login.set_defaults(func=login)
parser_map['login'] = parser_login

parser_logout = subparsers.add_parser('logout',
                                      help='Log out and remove credentials',
                                      description='Log out and remove credentials',
                                      prog='dx logout')
parser_logout.add_argument('--host', help='Log out of the given auth server host (port must also be given)')
parser_logout.add_argument('--port', type=int, help='Log out of the given auth server port (host must also be given)')
parser_logout.set_defaults(func=logout)
parser_map['logout'] = parser_logout

parser_select = subparsers.add_parser('select', help='List and select and project to switch to',
                                      prog='dx select')
parser_select.set_defaults(func=pick_and_set_project, save=False)
parser_map['select'] = parser_select

parser_invite = subparsers.add_parser('invite',
                                      help='Invite another user to a project',
                                      prog='dx invite')
parser_invite.add_argument('user', help='User to invite')
parser_invite.add_argument('project', help='Project to invite the user to')
parser_invite.add_argument('level', help='Permissions level the new member should have', choices=['LIST', 'VIEW', 'CONTRIBUTE', 'ADMINISTER'])
parser_invite.set_defaults(func=invite)
parser_map['invite'] = parser_invite

parser_ls = subparsers.add_parser('ls', help='List folders and objects in a folder',
                                  description='List folders and/or objects in a folder',
                                  parents=[no_color_arg],
                                  prog='dx ls')
parser_ls.add_argument('-a', '--all', help='show hidden files', action='store_true')
ls_output_args = parser_ls.add_mutually_exclusive_group()
ls_output_args.add_argument('-l', '--long', help='use a long listing format', action='store_true')
ls_output_args.add_argument('-i', '--id-only', dest='brief', action='store_true')
parser_ls.add_argument('--obj', help='show only objects', action='store_true')
parser_ls.add_argument('--folders', help='show only folders', action='store_true')
parser_ls.add_argument('--full', help='show full paths of folders', action='store_true')
parser_ls.add_argument('path', help='Folder (possibly in another project) to list the contents of, default is the current directory in the current project.  Syntax: projectID:/folder/path', nargs='?', default='.')
parser_ls.set_defaults(func=ls)
parser_map['ls'] = parser_ls

parser_cd = subparsers.add_parser('cd', help='Change the current working directory',
                                  description='Change the current working directory', prog='dx cd')
parser_cd.add_argument('path', help='Folder (possibly in another project) to which to change the current working directory, default is \"/\" in the current project', nargs='?', default='/')
parser_cd.set_defaults(func=cd)
parser_map['cd'] = parser_cd

parser_pwd = subparsers.add_parser('pwd', help='Print current working directory',
                                   description='Print current working directory', prog='dx pwd')
parser_pwd.set_defaults(func=pwd)
parser_map['pwd'] = parser_pwd

parser_mkdir = subparsers.add_parser('mkdir', help='Create a new folder',
                                     description='Create a new folder', prog='dx mkdir')
parser_mkdir.add_argument('-p', '--parents', help='no error if existing, create parent directories as needed', action='store_true')
parser_mkdir.add_argument('paths', help='Paths to folders to create', nargs='+')
parser_mkdir.set_defaults(func=mkdir)
parser_map['mkdir'] = parser_mkdir

parser_rmdir = subparsers.add_parser('rmdir', help='Remove a folder',
                                     description='Remove a folder', prog='dx rmdir')
parser_rmdir.add_argument('paths', help='Paths to folders to remove', nargs='+')
parser_rmdir.set_defaults(func=rmdir)
parser_map['rmdir'] = parser_rmdir

parser_rm = subparsers.add_parser('rm', help='Remove objects',
                                  description='Remove objects', prog='dx rm')
parser_rm.add_argument('paths', help='Paths to remove', nargs='+')
parser_rm.add_argument('-r', '--recursive', help='Recurse into a directory', action='store_true')
parser_rm.set_defaults(func=rm)
parser_map['rm'] = parser_rm

parser_rmproject = subparsers.add_parser('rmproject', help='Delete projects',
                                         description='Delete projects and all their associated data',
                                         prog='dx rmproject')
parser_rmproject.add_argument('projects', help='Projects to remove', nargs='+')
parser_rmproject.set_defaults(func=rmproject)
parser_map['rmproject'] = parser_rmproject

parser_mv = subparsers.add_parser('mv', help='Move objects and/or folders inside a single project',
                                  description='Move objects and/or folders inside a single project.',
                                  prog='dx mv')
parser_mv.add_argument('sources', help='Objects and/or folder names to move', nargs='+')
parser_mv.add_argument('destination', help='Folder into which to move the sources')
parser_mv.set_defaults(func=mv)
parser_map['mv'] = parser_mv

parser_cp = subparsers.add_parser('cp', help='Copy objects and/or folders between different projects',
                                  description='Copy objects and/or folders between different projects.  Folders will automatically be copied recursively.', prog='dx cp')
parser_cp.add_argument('sources', help='Objects and/or folder names to copy', nargs='+')
parser_cp.add_argument('destination', help='Folder into which to copy the sources')
parser_cp.set_defaults(func=cp)
parser_map['cp'] = parser_cp

parser_tree = subparsers.add_parser('tree', help='List folders and objects in a tree',
                                    description='List folders and objects in a tree',
                                    parents=[no_color_arg],
                                    prog='dx tree')
parser_tree.add_argument('-a', '--all', help='show hidden files', action='store_true')
parser_tree.add_argument('-l', '--long', help='use a long listing format', action='store_true')
parser_tree.add_argument('path', help='Folder (possibly in another project) to list the contents of, default is the current directory in the current project.  Syntax: projectID:/folder/path', nargs='?', default='.')
parser_tree.set_defaults(func=tree)
parser_map['tree'] = parser_tree

parser_get = subparsers.add_parser('get', help='Download a data object',
                                   description='Download the contents of a data object.  If downloading a gtable, the default format is tab-separated, but other formats can be requested via the flags --csv, --json, --vcf (as applicable), etc.  Downloading an applet will only download the source.  (Any bundled dependencies must be downloaded separately.)', prog='dx get')
parser_get.add_argument('path', help='Data object ID or name to access')
parser_get.add_argument('-o', '--output', help='local filename to be saved; if not supplied, the object\'s name on the platform will be used, along with any applicable extensions')
parser_get.add_argument('-f', '--overwrite', help='Overwrite the local file if necessary', action='store_true')
parser_get.add_argument('--stdout', help='Print data to stdout', action='store_true')
get_gtable_args = parser_get.add_argument_group(title='GTable-specific options')
get_gtable_args.add_argument('--no-header', help='Do not print a header in the CSV or TSV file', action='store_true')
get_gtable_args.add_argument('--no-rowid', help='Do not include the row ID column', action='store_true')
get_gtable_format_args = get_gtable_args.add_mutually_exclusive_group()
get_gtable_format_args.add_argument('--csv', help='Save the gtable in comma-separated format', action='store_true')
get_gtable_format_args.add_argument('--tsv', help='Save the gtable in tab-separated format (default if no format is specified)', action='store_true')
get_gtable_format_args.add_argument('--vcf', help='Save a Simplevar gtable as a VCF file', action='store_true')
parser_get.set_defaults(func=get)
parser_map['get'] = parser_get

parser_head = subparsers.add_parser('head',
                                    help='Print the first 10 lines of a file or first 10 rows of a gtable',
                                    parents=[no_color_arg],
                                    prog='dx head')
parser_head.add_argument('-n', '--lines', type=int, help='Print the first LINES number of lines or rows', default=10)
parser_head.add_argument('-w', '--max-col-width', type=int, help='Maximum width of each column to display', default=32)
parser_head.add_argument('path', help='File or gtable ID or name to access')
parser_head.set_defaults(func=head)
parser_map['head'] = parser_head

parser_cat = subparsers.add_parser('cat', help='Print file(s) to stdout', prog='dx cat')
parser_cat.add_argument('path', help='File ID or name(s) to print to stdout', nargs='+')
parser_cat.set_defaults(func=cat, output=None, stdout=True)
parser_map['cat'] = parser_cat

parser_gtable = subparsers.add_parser('gtable', help='Interact with remote gtables')
subparsers_gtable = parser_gtable.add_subparsers()
parser_map['gtable'] = parser_gtable

parser_gtable_get = subparsers_gtable.add_parser('get', help='Retrieve rows from a gtable',
                                                 parents=[stdout_args, json_arg],
                                                 prog='dx gtable get')
parser_gtable_get.add_argument('--starting', type=int, help='Specify starting row ID (provided by \'next\' if continuing a previous query) for the given query')
parser_gtable_get.add_argument('--limit', type=int, help='Specify a limit to the number of rows returned')
parser_gtable_get.add_argument('--gri', nargs=3, metavar=('CHR', 'LO', 'HI'), help='Specify chromosome name, low coordinate, and high coordinate for Genomic Range Index')
parser_gtable_get.add_argument('--gri-mode', help='Specify the mode of the GRI query (\'overlap\' or \'enclose\'; default \'overlap\')', default="overlap")
parser_gtable_get.add_argument('--gri-name', help='Override the default name of the Genomic Range Index (default: "gri"))', default="gri")
parser_gtable_get.add_argument('path', help='GTable ID from which to fetch rows')
parser_gtable_get.set_defaults(func=gtable_get)
parser_map['gtable get'] = parser_gtable_get

parser_describe = subparsers.add_parser('describe', help='Describe a remote object',
                                        description='Describe a DNAnexus entity.  Use this command to describe data objects by name or ID, jobs, apps, users, organizations, etc.  If using the "--json" flag, it will thrown an error if more than one match is found (but if you would like a JSON array of the describe hashes of all matches, then provide the "--multi" flag).  Otherwise, it will always display all results it finds.',
                                        parents=[json_arg, no_color_arg],
                                        prog='dx describe')
parser_describe.add_argument('--details', help='Include details if available', action='store_true')
parser_describe.add_argument('--multi', help='If the flag --json is also provided, then returns a JSON array of describe hashes of all matching results', action='store_true')
parser_describe.add_argument('path', help='Object ID or path to an object (possibly in another project) to describe.')
parser_describe.set_defaults(func=describe)
parser_map['describe'] = parser_describe

parser_close = subparsers.add_parser('close', help='Close a remote object', description='Close a remote object', prog='dx close')
parser_close.add_argument('path', help='Path to data object to close')
parser_close.add_argument('--wait', help='Wait for the object to close', action='store_true')
parser_close.set_defaults(func=close)
parser_map['close'] = parser_close

parser_build = subparsers.add_parser('build', help='Build an applet/app',
                                     description='Build an applet or app object from a local source directory',
                                     prog='dx build',
                                     add_help=False
)
parser_build.add_argument('builder_args', help='Arguments passed to the app builder', nargs=argparse.REMAINDER)
parser_build.set_defaults(func=build)
parser_map['build'] = parser_build

parser_install = subparsers.add_parser('install', help='Install an app', description='Install an app by name.', prog='dx install')
parser_install.add_argument('app', help='ID or name of app to install')
parser_install.set_defaults(func=install)
parser_map['install'] = parser_install

parser_uninstall = subparsers.add_parser('uninstall', help='Uninstall an app', description='Uninstall an app by name.', prog='dx uninstall')
parser_uninstall.add_argument('app', help='ID or name of app to uninstall')
parser_uninstall.set_defaults(func=uninstall)
parser_map['uninstall'] = parser_uninstall

parser_run = subparsers.add_parser('run', help='Run an applet or app', description=(fill('Run an applet or app.  If no inputs are specified, an interactive mode for selecting inputs will be launched.') + '''

SPECIFYING INPUTS

''' + fill('Other than the interactive mode, inputs can be specified by listing each field on the command line, or by giving the entire JSON string (where keys=input field names, values=field values).  Use the empty hash "{}" to signify no inputs.  Inputs cannot be specified by a mix of the different input flags.') + '\n\n  BY NAME\n\n' + fill('To use the "-i" flag to specify each input field name and value, using the syntax "-i<input name>=<input value>".  For example, the following runs the applet called "mapper" with 3 inputs called num (class int), str (class string), and gtables (class array:gtable):', initial_indent='  ', subsequent_indent='  ') + '''

    dx run mapper -inum=34 -istr=foo -igtables=reads1 -igtables=reads2

''' + fill('Note that the applet MUST have an input spec in order to parse the fields correctly between strings and gtable names.  The same input field can be used multiple times if the input class is an array.', initial_indent='  ', subsequent_indent='  ') + '\n\n  FULL JSON\n\n' + fill('If providing the full input JSON, it can be done using one of the following flags:', initial_indent='  ', subsequent_indent='  ') + '''

    1) -j/--input_json INPUT_JSON
    2) -f/--input_json_file FILENAME
    3) --stdin

  JOB-BASED OBJECT REFERENCES

''' + fill('For now, job-based object references can only be used if provided as part of a full input JSON.', initial_indent='  ', subsequent_indent='  ') + '\n'), prog='dx run', formatter_class=argparse.RawTextHelpFormatter, parents=[stdout_args])
parser_run.add_argument('path', help='Name or ID of applet or app to run')
parser_run.add_argument('--alias', '--version', '--tag', dest='alias',
                        help=fill('Tag or version of the app to run (default: \"default\" if an app)', width_adjustment=-24))
parser_run.add_argument('--folder', help=fill('The project:folder path in which to output the results.  By default, the current working directory will be used.', width_adjustment=-24))
parser_run.add_argument('-y', '--yes', dest='confirm', help='Do not ask for confirmation', action='store_false')
parser_run.add_argument('--wait', help='Wait until the job is done before returning', action='store_true')
parser_run.add_argument('--watch', help="Watch the job after launching it", action='store_true')
parser_run_input = parser_run.add_mutually_exclusive_group()
parser_run_input.add_argument('-i', '--input', help='''An input to be added using "<input name>=<input value>"
Examples:
  -ichunkSize=250000     # Numerical input
  -iname=\'\"hello world\"\' # Quotes required for strings
  -ireads=reads_name     # Names will be resolved''', action='append')
parser_run_input.add_argument('-j', '--input-json', help=fill('The full input JSON (keys=input field names, values=input field values)', width_adjustment=-24))
parser_run_input.add_argument('-f', '--input-json-file', dest='filename', help=fill('Load input JSON from the file'))
parser_run_input.add_argument('--stdin', help=fill('Interprets inputs from stdin instead of using the -i flags.  Format should be in the raw JSON with keys equal to the input names and values equal to their values.', width_adjustment=-24), action='store_true')
parser_run.set_defaults(func=run, verbose=False)
parser_map['run'] = parser_run

parser_watch = subparsers.add_parser('watch', help='Watch a job and its sub-jobs', prog='dx watch')
parser_watch.add_argument('jobid', help='ID of the job to watch')
parser_watch.add_argument('-n', '--num-recent-messages', help='Number of recent messages to get', default=9999999999)
parser_watch.add_argument('--no-subjobs', help='Do not watch messages from subjobs')
parser_watch.set_defaults(func=watch)
parser_map['watch'] = parser_watch

parser_terminate = subparsers.add_parser('terminate', help='Terminate a job that has not yet finished', prog='dx terminate')
parser_terminate.add_argument('jobid', help='ID of the job to terminate')
parser_terminate.set_defaults(func=terminate)
parser_map['terminate'] = parser_terminate

parser_find = subparsers.add_parser('find', help='Search functionality over data objects, projects, and jobs',
                                    description='Search functionality over data objects, projects, and jobs', prog='dx find')
subparsers_find = parser_find.add_subparsers()
subparsers_find.metavar = 'category'
parser_map['find'] = parser_find

parser_find_jobs = subparsers_find.add_parser('jobs', help='Finds jobs', description='Finds jobs with the given search parameters.  Output is formatted to show origin jobs on the left with its children jobs indented underneath it.  Output string includes the job ID, the time at which the job was created, and its current state.', parents=[stdout_args, json_arg, no_color_arg], prog='dx find jobs')
parser_find_jobs.add_argument('--user', help='User ID who launched the job')
parser_find_jobs.add_argument('--applet', help='Applet ID that job is running')
parser_find_jobs.add_argument('--project', help='Project context ID (output project)')
parser_find_jobs.add_argument('--state', help='State of the job, e.g. \"done\", \"failed\"')
parser_find_jobs.add_argument('--origin', help='Job ID of the top-level (user-initiated) job')
parser_find_jobs.add_argument('--parent', help='Job ID of the parent job, or the string \'none\' to indicate no parent')
parser_find_jobs.add_argument('--created-after', help='Timestamp after which the job was last created (negative number means ms in the past, or use suffix s, m, h, d, w, M, y')
parser_find_jobs.add_argument('--created-before', help='Timestamp before which the job was last created (negative number means ms in the past, or use suffix s, m, h, d, w, M, y)')
parser_find_jobs.add_argument('-n', '--num-results', type=int, help='Max number of origin jobs to return')
parser_find_jobs.set_defaults(func=find_jobs)
parser_map['find jobs'] = parser_find_jobs

parser_find_data = subparsers_find.add_parser('data', help='Finds data objects', parents=[stdout_args, json_arg, no_color_arg, no_glob_arg], prog='dx find data')
parser_find_data.add_argument('--class', dest='classname', choices=['record', 'file', 'gtable', 'applet', 'table'], help='Data object class')
parser_find_data.add_argument('--state', choices=['open', 'closing', 'closed', 'any'], help='State of the object')
parser_find_data.add_argument('--visibility', choices=['hidden', 'visible', 'either'], default='visible', help='Whether the object is hidden or not')
parser_find_data.add_argument('--name', help='Name of the object')
parser_find_data.add_argument('--properties', nargs='+', help='Key-value pairs of properties, e.g. \'--properties property_key=property_value another_property_key=another_property_value\'')
parser_find_data.add_argument('--type', help='Type of the data object')
parser_find_data.add_argument('--tag', help='Tag of the data object')
parser_find_data.add_argument('--link', help='Object ID that the data object links to')
parser_find_data.add_argument('--project', help='Project with which to restrict the results')
parser_find_data.add_argument('--folder', help='Folder path with which to restrict the results (\'--project\' must be used in this case)')
parser_find_data.add_argument('--recurse', help='Recurse into subfolders', action='store_true')
parser_find_data.add_argument('--mod-after', help='Timestamp after which the object was last modified (negative number means ms in the past, or use suffix s, m, h, d, w, M, y)')
parser_find_data.add_argument('--mod-before', help='Timestamp before which the object was last modified (negative number means ms in the past, or use suffix s, m, h, d, w, M, y)')
parser_find_data.add_argument('--created-after', help='Timestamp after which the object was created (negative number means ms in the past, or use suffix s, m, h, d, w, M, y)')
parser_find_data.add_argument('--created-before', help='Timestamp before which the object was created (negative number means ms in the past, or use suffix s, m, h, d, w, M, y)')
parser_find_data.set_defaults(func=find_data)
parser_map['find data'] = parser_find_data

parser_find_projects = subparsers_find.add_parser('projects', help='Finds projects', parents=[stdout_args, json_arg], prog='dx find projects')
parser_find_projects.add_argument('--name', help='Name of the project')
parser_find_projects.add_argument('--level', choices=['LIST', 'VIEW', 'CONTRIBUTE', 'ADMINISTER'], help='Minimum level of permissions expected')
parser_find_projects.add_argument('--public', help='Include public projects', action='store_true')
parser_find_projects.set_defaults(func=find_projects)
parser_map['find projects'] = parser_find_projects

parser_find_apps = subparsers_find.add_parser('apps', help='Finds apps', parents=[stdout_args, json_arg], prog='dx find apps')
parser_find_apps.add_argument('--name', help='Name of the app')
parser_find_apps.add_argument('--category', help='Category of the app')
parser_find_apps.add_argument('-a', '--all', help='Whether to return all versions of the app', action='store_true')
parser_find_apps.add_argument('--unpublished', help='Whether to return unpublished apps as well', action='store_true')
parser_find_apps.add_argument('--installed', help='Whether to restrict the list to installed apps only', action='store_true')
parser_find_apps.add_argument('--billed-to', help='User or organization responsible for the app')
parser_find_apps.add_argument('--creator', help='Creator of the app version')
parser_find_apps.add_argument('--developer', help='Developer of the app')
parser_find_apps.add_argument('--created-after', help='Timestamp after which the app version was created (negative number means ms in the past, or use suffix s, m, h, d, w, M, y)')
parser_find_apps.add_argument('--created-before', help='Timestamp before which the app version was created (negative number means ms in the past, or use suffix s, m, h, d, w, M, y)')
parser_find_apps.add_argument('--mod-after', help='Timestamp after which the app was last modified (negative number means ms in the past, or use suffix s, m, h, d, w, M, y)')
parser_find_apps.add_argument('--mod-before', help='Timestamp before which the app was last modified (negative number means ms in the past, or use suffix s, m, h, d, w, M, y)')
parser_find_apps.set_defaults(func=find_apps)
parser_map['find apps'] = parser_find_apps

parser_dataobject_args = argparse.ArgumentParser(add_help=False)
parser_dataobject_args_gp = parser_dataobject_args.add_argument_group('metadata arguments')
parser_dataobject_args_gp.add_argument('--visibility', choices=['hidden', 'visible'], default='visible', help='Whether the object is hidden or not')
parser_dataobject_args_gp.add_argument('--name', help='Name of the object')
parser_dataobject_args_gp.add_argument('--properties', nargs='+', help='Key-value pairs of properties, e.g. \'--properties property_key=property_value another_property_key=another_property_value\'')
parser_dataobject_args_gp.add_argument('--types', nargs='+', help='Types of the data object')
parser_dataobject_args_gp.add_argument('--tags', nargs='+', help='Tags of the data object')
parser_dataobject_args_gp.add_argument('--project', help='Project (if not using the default project)')
parser_dataobject_args_gp.add_argument('--details', help='JSON to store as details')
parser_dataobject_args_gp.add_argument('--parents', help='Create folder (and its parents) if necessary', action='store_true')
parser_dataobject_args_gp.add_argument('--folder', help='Folder path with which to restrict the results (\'--project\' must be used in this case)')

parser_upload = subparsers.add_parser('upload', help='Upload a file', parents=[parser_dataobject_args], prog="dx upload")
parser_upload.add_argument('filename', help='local filename to upload')
parser_upload.add_argument('--brief', help='Print ID of the file object instead of the full description', action='store_true')
parser_upload.add_argument('--wait', help='Wait until the file has finished closing', action='store_true')
parser_upload.set_defaults(func=upload)
parser_map['upload'] = parser_upload

parser_import = subparsers.add_parser('import',
                                      help='Import (convert and upload) a table or genomic file',
                                      description='Import a table or genomic file as a GenomicTable.  If no flags are given, the file given will be interpreted based on its contents.  The type of the GenomicTable will be automatically set if applicable (e.g. Reads, etc.).',
                                      parents=[stdout_args, json_arg, no_color_arg, parser_dataobject_args],
                                      prog='dx import')
parser_import.add_argument('filename', help='local filename to import')
parser_import.add_argument('--wait', help='Wait until the GTable has finished closing', action='store_true')
import_format_args = parser_import.add_argument_group('input format arguments')
import_format_args_gp = import_format_args.add_mutually_exclusive_group()
import_format_args_gp.add_argument('--csv', help='Interpret the file as a comma-separated format', action='store_true')
import_format_args_gp.add_argument('--tsv', help='Interpret the file as a tab-separated format (default if no format is specified and a file extension is not recognized)', action='store_true')
import_format_args_gp.add_argument('--vcf', help='Interpret the file as a VCF file', action='store_true')
import_format_args.add_argument('--column-names', help='Comma-separated list of column names to use; types (if not string) can be specified using "name:type" syntax.  If not given, the first line of the file will be used to infer column names.')
parser_import.set_defaults(func=dximport)
parser_map['import'] = parser_import

parser_export = subparsers.add_parser('export',
                                      help='Export a GenomicTable into a local file',
                                      description='Export a GenomicTable into a local file.\n\nSupported formats:\n\n  ' + '\n  '.join(exporters.keys()),
                                      parents=[],
                                      formatter_class=argparse.RawTextHelpFormatter,
                                      prog='dx export')

parser_export.add_argument('format', help='Format to export to')
parser_export.add_argument('exporter_args', help=fill('Arguments passed to the exporter', width_adjustment=-24), nargs=argparse.REMAINDER)
parser_export.set_defaults(func=export)
parser_map['export'] = parser_export

parser_new = subparsers.add_parser('new', help='Create a new data object', prog="dx new")
subparsers_new = parser_new.add_subparsers()
subparsers_new.metavar = 'class'
parser_map['new'] = parser_new

parser_new_project = subparsers_new.add_parser('project', help='Create a new project',
                                               parents=[stdout_args],
                                               prog='dx new project')
parser_new_project.add_argument('name', help='Name of the new project')
parser_new_project.set_defaults(func=new_project)
parser_map['new project'] = parser_new_project

parser_new_record = subparsers_new.add_parser('record', help='Create a new record',
                                              parents=[parser_dataobject_args],
                                              prog='dx new record')
parser_new_record.add_argument('--init', help='Record ID from which to initialize all metadata')
parser_new_record.set_defaults(func=new_record)
parser_map['new record'] = parser_new_record

parser_new_gtable = subparsers_new.add_parser('gtable', help='Create a new gtable', parents=[parser_dataobject_args], prog='dx new gtable')
parser_new_gtable.add_argument('--columns', help='JSON for specifying the columns')
parser_new_gtable.add_argument('--indices', help='JSON for specifying the indices')
parser_new_gtable.add_argument('--input', help='a filename containing the JSON input to be used (currently only used for overriding --columns and --indices)')
parser_new_gtable.set_defaults(func=new_gtable)
parser_map['new gtable'] = parser_new_gtable

parser_get_details = subparsers.add_parser('get_details', help='Get details of an object', prog="dx get_details")
parser_get_details.add_argument('path', help='Data object to get details for')
parser_get_details.set_defaults(func=get_details)
parser_map['get_details'] = parser_get_details

parser_set_details = subparsers.add_parser('set_details', help='Set details on an object', prog="dx set_details")
parser_set_details.add_argument('path', help='Data object to modify')
parser_set_details.add_argument('details', help='JSON to store as details')
parser_set_details.set_defaults(func=set_details)
parser_map['set_details'] = parser_set_details

parser_set_visibility = subparsers.add_parser('set_visibility', help='Set visibility on an object', prog='dx set_visibility')
parser_set_visibility.add_argument('path', help='Data object to modify')
parser_set_visibility.add_argument('visibility', choices=['hidden', 'visible'], help='Visibility that the object should have')
parser_set_visibility.set_defaults(func=set_visibility)
parser_map['set_visibility'] = parser_set_visibility

parser_add_types = subparsers.add_parser('add_types', help='Add types to an object', prog='dx add_types')
parser_add_types.add_argument('path', help='Data object to modify')
parser_add_types.add_argument('types', nargs='+', help='Types to add')
parser_add_types.set_defaults(func=add_types)
parser_map['add_types'] = parser_add_types

parser_remove_types = subparsers.add_parser('remove_types', help='Remove types from an object', prog='dx remove_types')
parser_remove_types.add_argument('path', help='Data object to modify')
parser_remove_types.add_argument('types', nargs='+', help='Types to remove')
parser_remove_types.set_defaults(func=remove_types)
parser_map['remove_types'] = parser_remove_types

parser_tag = subparsers.add_parser('tag', help='Tag an object', prog='dx tag')
parser_tag.add_argument('path', help='Data object to modify')
parser_tag.add_argument('tags', nargs='+', help='Tags to add')
parser_tag.set_defaults(func=add_tags)
parser_map['tag'] = parser_tag

parser_untag = subparsers.add_parser('untag', help='Untag an object', prog='dx untag')
parser_untag.add_argument('path', help='Data object to modify')
parser_untag.add_argument('tags', nargs='+', help='Tags to remove')
parser_untag.set_defaults(func=remove_tags)
parser_map['untag'] = parser_untag

parser_rename = subparsers.add_parser('rename',
                                      help='Rename a project, folder, or object',
                                      description='Rename a project, folder, or object.  To indicate a project, append a colon character ":" after the project ID or name',
                                      prog='dx rename')
parser_rename.add_argument('path', help='Path to project, folder, or object to rename')
parser_rename.add_argument('name', help='New name')
parser_rename.set_defaults(func=rename)
parser_map['rename'] = parser_rename

parser_set_properties = subparsers.add_parser('set_properties', help='Set properties of an object', prog='dx set_properties')
parser_set_properties.add_argument('path', help='Data object to modify')
parser_set_properties.add_argument('properties', nargs='+', help='Key-value pairs of properties, e.g. \'property_key=property_value another_property_key=another_property_value\'')
parser_set_properties.set_defaults(func=set_properties)
parser_map['set_properties'] = parser_set_properties

parser_unset_properties = subparsers.add_parser('unset_properties', help='Unset properties of an object', prog='dx unset_properties')
parser_unset_properties.add_argument('path', help='Data object to modify')
parser_unset_properties.add_argument('properties', nargs='+', help='Property names to unset')
parser_unset_properties.set_defaults(func=unset_properties)
parser_map['unset_properties'] = parser_unset_properties

parser_api = subparsers.add_parser('api', help='Make an API call', prog='dx api')
parser_api.add_argument('resource', help='is one of \"system\", a class name (e.g. \"record\"), or an entity ID such as \"record-xxxx\"')
parser_api.add_argument('method', help='a valid method for the resource as documented by the API document')
parser_api.add_argument('input_json', nargs='?', default="{}", help='the JSON input for the method as documented by the API document (if not given, \"{}\" is used)')
parser_api.add_argument('--input', help='a filename containing the JSON input to be used (takes precedence over the \'json\' argument)')
parser_api.add_argument('--stdin', help='Indicate that JSON input will be provided with a prompt', action='store_true')
parser_api.set_defaults(func=api)
parser_map['api'] = parser_api

# "Execution" starts here

# Take in things from the pipe, respecting quoted substrings
if len(args_list) > 0:
    args = parser.parse_args(args_list)
    set_cli_colors(args)
    args.func(args)
else:
    parser.print_help()
    sys.exit(1)
